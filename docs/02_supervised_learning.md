# æ•™å¸«ã‚ã‚Šå­¦ç¿’ (1)

å‚™ãˆã¾ã™ã€‚





```python
import numpy as np
import scipy as sp
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib
matplotlib.rc('font', family='IPAexGothic') # æ—¥æœ¬èªãƒ—ãƒ­ãƒƒãƒˆè¨­å®š
import mglearn
```

## ã‚¯ãƒ©ã‚¹åˆ†é¡ã¨å›å¸°

æ•™å¸«ã‚ã‚Šå­¦ç¿’ã¯ã•ã‚‰ã«2ã¤ã«åˆ†ã‘ã‚‰ã‚Œã‚‹ã€‚

- **ã‚¯ãƒ©ã‚¹åˆ†é¡**: ã‚¯ãƒ©ã‚¹ãƒ©ãƒ™ãƒ«ã‚’äºˆæ¸¬ã™ã‚‹å•é¡Œã€‚
    - 2ã‚¯ãƒ©ã‚¹åˆ†é¡ (binary classification): Yes/Noã¿ãŸã„ãª2æŠã€‚
        - ç‰‡æ–¹ã‚’**é™½æ€§** (positive)ã€ã‚‚ã†ç‰‡æ–¹ã‚’**é™°æ€§** (negative)ã¨ã™ã‚‹å ´åˆãŒã—ã°ã—ã°ã‚ã‚‹ã€‚
    - ä»–ã‚¯ãƒ©ã‚¹åˆ†é¡ (multiclass classification): ã‚‚ã£ã¨é¸æŠè‚¢å¤šã„ã‚„ã¤ã€‚
- **å›å¸°**: é€£ç¶šå€¤ã‚’äºˆæ¸¬ã™ã‚‹å•é¡Œã€‚

2ã¤ã‚’åŒºåˆ¥ã™ã‚‹ã®ã¯**å‡ºåŠ›**ãŒé€£ç¶šã‹ã©ã†ã‹ã€‚**å…¥åŠ›**ã¯ã©ã¡ã‚‰ã®å•é¡Œã§ã‚‚é€£ç¶šã®å ´åˆã‚‚é›¢æ•£çš„ãªå ´åˆã‚‚ã‚ã‚‹ã€‚

## æ±åŒ–ã€éå‰°é©åˆã€é©åˆä¸è¶³

- **æ±åŒ–èƒ½åŠ›**: æœªçŸ¥ã®ãƒ‡ãƒ¼ã‚¿(è¨“ç·´ã«ä½¿ã£ã¦ãªã„ãƒ‡ãƒ¼ã‚¿)ã«å¯¾ã™ã‚‹æ­£ã—ã„å€¤ã‚’äºˆæ¸¬ã™ã‚‹èƒ½åŠ›ã€‚
- **éå‰°é©åˆ**: è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¯ã‚ã£ã¡ã‚ƒæ­£ç¢ºã«äºˆæ¸¬ã§ãã‚‹ã‘ã©æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã¯ã¦ã‚“ã§ãƒ€ãƒ¡ã¨ã„ã†çŠ¶æ…‹ã€‚
- **é©åˆä¸è¶³**: è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã™ã‚‰ã¡ã‚ƒã‚“ã¨äºˆæ¸¬ã§ãã¦ãªã„ã¨ã„ã†çŠ¶æ…‹ã€‚

ä¸€èˆ¬çš„ã«ã¯**ãƒ¢ãƒ‡ãƒ«ã‚’è¤‡é›‘ã«ã™ã‚‹**ã»ã©è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã«é©åˆã—ã¦ã„ãã€‚é©åˆä¸è¶³ã§ãªãã€éå‰°é©åˆã«ãªã‚‰ãªã„é©åº¦ãªãƒ¢ãƒ‡ãƒ«ã®è¤‡é›‘ã•ã®æ™‚ã«æ±åŒ–èƒ½åŠ›ãŒæœ€å¤§ã«ãªã‚‹ã€‚ãã“ã‚’ç›®æŒ‡ãã†ã€‚

### ãƒ¢ãƒ‡ãƒ«ã®è¤‡é›‘ã•ã¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®å¤§ãã•

- ãƒ¢ãƒ‡ãƒ«ãŒè¤‡é›‘ã§ã‚‚ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒå¤§ãã‘ã‚Œã°éå‰°é©åˆã‚’é¿ã‘ã‚‰ã‚Œã‚‹ã€‚
- é©åº¦ãªè¤‡é›‘ã•ã®ãƒ¢ãƒ‡ãƒ«ã¨ååˆ†ã«å¤§ããªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ã†ã“ã¨ãŒæˆåŠŸã®ãƒã‚¤ãƒ³ãƒˆã€‚

## æ•™å¸«ã‚ã‚Šæ©Ÿæ¢°å­¦ç¿’ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 

### ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ

- **äººå·¥çš„ãªå˜ç´”ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ**ã¨ã€**å®Ÿä¸–ç•Œã®å‰²ã¨è¤‡é›‘ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ**ã‚’ä½¿ã†ã€‚

#### äººå·¥çš„ãªå˜ç´”ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ

å˜ç´”ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯**mglearn**ã§ç”Ÿæˆã™ã‚‹ã€‚

- **forge**: `mglearn.datasets.make_forge()`ã§ç”Ÿæˆã™ã‚‹2ã‚¯ãƒ©ã‚¹åˆ†é¡å‘ã‘ãƒ‡ãƒ¼ã‚¿ã€‚
    - 2ã¤ã®ç‰¹å¾´é‡ã¨1ã¤ã®2å€¤ç›®çš„å¤‰æ•°ã‚’ã‚‚ã¤ã€‚


```python
X, y = mglearn.datasets.make_forge()
mglearn.discrete_scatter(X[:, 0], X[:, 1], y)
plt.legend(["Class 0", "Class 1"], loc = 4) # å‡¡ä¾‹
plt.xlabel("ç¬¬1ç‰¹å¾´é‡")
plt.ylabel("ç¬¬2ç‰¹å¾´é‡")
```

![](02_supervised_learning_files/figure-html/unnamed-chunk-3-1.png)<!-- -->

- **wave**: `mglearn.datasets.make_wave`ã§ç”Ÿæˆã™ã‚‹å›å¸°å‘ã‘ãƒ‡ãƒ¼ã‚¿ã€‚
    - 1ã¤ã®ç‰¹å¾´é‡ã¨1ã¤ã®ç›®çš„å¤‰æ•°ã‚’æŒã¤ã€‚


```python
X, y = mglearn.datasets.make_wave(n_samples = 40)
plt.plot(X, y, 'o')
plt.xlabel("ç‰¹å¾´é‡")
plt.ylabel("ç›®çš„å¤‰æ•°")
```

![](02_supervised_learning_files/figure-html/unnamed-chunk-5-1.png)<!-- -->

#### å®Ÿãƒ‡ãƒ¼ã‚¿

å®Ÿãƒ‡ãƒ¼ã‚¿ã¯**scikit-learn**ã«å…¥ã£ã¦ã‚‹ã‚‚ã®ã‚’ä½¿ã†ã€‚ç¬¬1ç« ã§ã‚‚èª¬æ˜ã—ãŸBunchã‚¯ãƒ©ã‚¹ã«ãªã£ã¦ã„ã‚‹ã€‚

- **cancer**: ã‚¦ã‚£ã‚¹ã‚³ãƒ³ã‚·ãƒ³ä¹³ç™Œãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
    - ç›®çš„å¤‰æ•°ã¯è‰¯æ€§(benign)ã¨æ‚ªæ€§(malignant)ã®2å€¤ã€‚
    - ç‰¹å¾´é‡ã¯30ã€‚
    - ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆã¯569ç‚¹ã€‚


```python
from sklearn.datasets import load_breast_cancer
cancer = load_breast_cancer()
print(cancer.keys())
 ## dict_keys(['target', 'data', 'DESCR', 'target_names', 'feature_names'])
print(cancer.data.shape)
 ## (569, 30)
print(cancer.target_names)
 ## ['malignant' 'benign']
print(np.bincount(cancer.target))
 ## [212 357]
```

- **boston_housing**: 1970å¹´ä»£ã®ãƒœã‚¹ãƒˆãƒ³è¿‘éƒŠã®ä½å®…ä¾¡æ ¼ã€‚
    - ä½å®…ä¾¡æ ¼ã®ä¸­å¤®å€¤ãŒç›®çš„å¤‰æ•°ã€‚
    - ç‰¹å¾´é‡ã¯13ã€‚
    - ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆã¯506ç‚¹ã€‚


```python
from sklearn.datasets import load_boston
boston = load_boston()
print(boston.data.shape)
 ## (506, 13)
print(boston.feature_names)
 ## ['CRIM' 'ZN' 'INDUS' 'CHAS' 'NOX' 'RM' 'AGE' 'DIS' 'RAD' 'TAX' 'PTRATIO'
 ##  'B' 'LSTAT']
```

- ç‰¹å¾´é‡åŒå£«ã®ç©ã‚’æ±‚ã‚ãŸã‚Šã—ã¦ã€æ–°ã—ã„ç‰¹å¾´é‡ã‚’å°å‡ºã™ã‚‹ã“ã¨ã‚’**ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°**ã¨å‘¼ã¶ã€‚
- **boston_housing**ã«å¯¾ã—ã€é‡è¤‡ã‚ã‚Šã§2ã¤ã®ç‰¹å¾´é‡ã®ç©ã‚’æ±‚ã‚ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æ‹¡å¼µã‚’è©¦ã¿ã‚‹ã€‚
    - ä½œæ¥­ãŒé¢å€’ãªã®ã§æ—¢ã«æ‹¡å¼µã—ãŸã‚‚ã®ãŒ`mglearn.datasets.load_extended_boston()`ã§èª­ã¿è¾¼ã‚ã¾ã™ã€‚


```python
X, y = mglearn.datasets.load_extended_boston()
print(X.shape)
 ## (506, 104)
```


## ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 1 $k$-æœ€è¿‘å‚æ³•

- a.k.a. $k$-NN
- è¿‘ã„ã‚„ã¤ã¯å¤§ä½“ãŠã‚“ãªã˜ã€‚

### $k$-æœ€è¿‘å‚æ³•ã«ã‚ˆã‚‹ã‚¯ãƒ©ã‚¹åˆ†é¡

- $k$ã¯å‚è€ƒã«ã™ã‚‹è¿‘å‚ç‚¹ã®å€‹æ•°ã€‚
- 1-NNã®ä¾‹ã€‚


```python
mglearn.plots.plot_knn_classification(n_neighbors=1)
```

![](02_supervised_learning_files/figure-html/unnamed-chunk-10-1.png)<!-- -->

- 3-NNã®ä¾‹
    - è¿‘å‚ç‚¹ãŒè¤‡æ•°ã®ã¨ãã¯å¤šæ•°æ±ºã§æ±ºã‚ã‚‹ã€‚


```python
mglearn.plots.plot_knn_classification(n_neighbors=3)
```

![](02_supervised_learning_files/figure-html/unnamed-chunk-12-1.png)<!-- -->

- **scikit-learn**ã§ã‚„ã‚‹ã€‚


```python
from sklearn.model_selection import train_test_split
X, y = mglearn.datasets.make_forge()
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)
from sklearn.neighbors import KNeighborsClassifier
clf = KNeighborsClassifier(n_neighbors=3).fit(X_train, y_train)
print(clf.score(X_test, y_test))
 ## 0.8571428571428571
```

### KNeighborsClassifierã®è§£æ

- ç‰¹å¾´é‡ãŒ2ã¤ã—ã‹ãªã‘ã‚Œã°ã€æ•£å¸ƒå›³ãŒæã‘ã‚‹ã€‚
- æ•£å¸ƒå›³ä¸Šã®ã‚ã‚‰ã‚†ã‚‹ç®‡æ‰€ã«ã¤ã„ã¦**ã‚‚ã—ãã®å ´æ‰€ã«ç‚¹ãŒã‚ã£ãŸã‚‰**ã¨è€ƒãˆã¦åˆ¤åˆ¥ãŒã§ãã‚‹ã€‚
- ã¤ã¾ã‚Šã€ç‰¹å¾´é‡ãŒã¤ãã‚‹å¹³é¢ã‚’åˆ†é¡ã‚¯ãƒ©ã‚¹ã§å¡—ã‚Šåˆ†ã‘ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚
- å¢ƒç•Œç·šã‚’**æ±ºå®šå¢ƒç•Œ**ã¨å‘¼ã¶ã€‚


```python
fig, axes = plt.subplots(1, 3, figsize = (10, 3))
for n, ax in zip([1, 3, 9], axes):
    clf = KNeighborsClassifier(n_neighbors = n).fit(X, y)
    mglearn.plots.plot_2d_separator(clf, X, fill=True, eps = 0.5, ax = ax, alpha = .4)
    mglearn.discrete_scatter(X[:, 0], X[:, 1], y, ax = ax)
    ax.set_title("{} neighbor(s)".format(n))
    ax.set_xlabel("ç‰¹å¾´é‡ 0")
    ax.set_ylabel("ç‰¹å¾´é‡ 1")
axes[0].legend(loc=3)
```

![](02_supervised_learning_files/figure-html/unnamed-chunk-15-1.png)<!-- -->

- è¿‘å‚ç‚¹ãŒå¤šã„ã»ã©å¢ƒç•ŒãŒãªã‚ã‚‰ã‹ = ãƒ¢ãƒ‡ãƒ«ã¯å˜ç´”ã«ãªã‚‹ã€‚
    - è¿‘å‚ç‚¹1 = æœ€ã‚‚è¤‡é›‘ãªãƒ¢ãƒ‡ãƒ«
    - è¿‘å‚ç‚¹æ•° = ãƒ‡ãƒ¼ã‚¿æ•° -> ãŸã ã®å¤šæ•°æ±º
- ã¨ã„ã†ã“ã¨ã¯è¿‘å‚ç‚¹æ•°ã®æ•°ã‚’å¢—ã‚„ã—ã¦ã„ãã¨ã€ã©ã“ã‹ã§æ±åŒ–èƒ½åŠ›ã®ãƒ”ãƒ¼ã‚¯ãŒâ€¦ï¼Ÿ
- **cancer**ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§è©¦ã—ã¦ã¿ã‚‹ã€‚


```python
from sklearn.datasets import load_breast_cancer
cancer = load_breast_cancer()
X_train, X_test, y_train, y_test = train_test_split(
  cancer.data, cancer.target, stratify = cancer.target, random_state = 66
)
training_accuracy = []
test_accuracy = []
n_settings = range(1, 11)
for n in n_settings:
  clf = KNeighborsClassifier(n_neighbors = n).fit(X_train, y_train)
  training_accuracy.append(clf.score(X_train, y_train))
  test_accuracy.append(clf.score(X_test, y_test))
plt.plot(n_settings, training_accuracy, label = "è¨“ç·´ã‚»ãƒƒãƒˆç²¾åº¦")
plt.plot(n_settings, test_accuracy, label = "ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆç²¾åº¦")
plt.ylabel("ç²¾åº¦")
plt.xlabel("è¿‘å‚ç‚¹æ•°")
plt.legend()
```

![](02_supervised_learning_files/figure-html/unnamed-chunk-17-1.png)<!-- -->

### $k$-è¿‘å‚å›å¸°

- kNNã¯å›å¸°ã‚‚ã§ãã‚‹ã€‚
- 1-NNã§ã¯è¿‘å‚ç‚¹ã®å€¤ãŒæ–°ã—ã„è¦³æ¸¬å€¤ã«å¯¾å¿œã™ã‚‹å€¤ã ã¨è€ƒãˆã‚‹ã€‚


```python
mglearn.plots.plot_knn_regression(n_neighbors = 1)
```

![](02_supervised_learning_files/figure-html/unnamed-chunk-19-1.png)<!-- -->

  
- è¿‘å‚ç‚¹ãŒè¤‡æ•°ã®æ™‚ã¯å¹³å‡å€¤ã‚’ä½¿ã†ã€‚


```python
mglearn.plots.plot_knn_regression(n_neighbors = 3)
```

![](02_supervised_learning_files/figure-html/unnamed-chunk-21-1.png)<!-- -->

- **scikit-learn**ã§ã¯ã€**KNeighborsRegressor**ã‚¯ãƒ©ã‚¹ã«å®Ÿè£…ã•ã‚Œã¦ã‚‹ã€‚


```python
from sklearn.neighbors import KNeighborsRegressor
X, y = mglearn.datasets.make_wave(n_samples = 40)
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)
reg = KNeighborsRegressor(n_neighbors = 3).fit(X_train, y_train)
print(reg.score(X_test, y_test))
 ## 0.8344172446249604
```

### KNeighborsRegressorã®è§£æ

- 1æ¬¡å…ƒã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«å¯¾ã™ã‚‹äºˆæ¸¬å€¤ã¯ã€è¿‘å‚ç‚¹æ•°$k$ã«å¯¾ã—ã¦ã©ã®ã‚ˆã†ã«å¤‰åŒ–ã™ã‚‹ã‹ï¼Ÿ


```python
# ãƒ—ãƒ­ãƒƒãƒˆå…ˆã‚’3ã¤ä½œã‚‹
fig, axes = plt.subplots(1, 3, figsize = (15, 4))
# -3ã€œ3ã¾ã§ã®é–“ã«ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆã‚’1000ç‚¹ä½œã‚‹
line = np.linspace(-3, 3, 1000).reshape(-1, 1)
for n_neighbors, ax in zip([1, 3, 9], axes):
  reg = KNeighborsRegressor(n_neighbors = n_neighbors)
  reg.fit(X_train, y_train)
  ax.plot(line, reg.predict(line))
  ax.plot(X_train, y_train, '^')
  ax.plot(X_test, y_test, 'v')
  ax.set_title(
    "{} è¿‘å‚ç‚¹\n è¨“ç·´ã‚¹ã‚³ã‚¢: {:.2f} ãƒ†ã‚¹ãƒˆã‚¹ã‚³ã‚¢{:.2f}".format(
      n_neighbors, reg.score(X_train, y_train), reg.score(X_test, y_test)))
  ax.set_xlabel("ç‰¹å¾´é‡")
  ax.set_ylabel("ç›®çš„å¤‰æ•°")
  
axes[0].legend(["ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹äºˆæ¸¬å€¤", "è¨“ç·´ãƒ‡ãƒ¼ã‚¿", "ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿"], loc="best")
```

![](02_supervised_learning_files/figure-html/unnamed-chunk-24-1.png)<!-- -->

- $k=1$ã®å ´åˆã¯äºˆæ¸¬å€¤ãŒå…¨ã¦ã®è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚’é€šã‚‹ã®ã§ã€ãƒ¢ãƒ‡ãƒ«ãŒä¸å®‰å®šã«ãªã‚‹ã€‚
- è¿‘å‚ç‚¹ã‚’å¢—ã‚„ã—ã¦ã„ãã¨äºˆæ¸¬ã¯æ»‘ã‚‰ã‹ã«ãªã‚‹ãŒã€ãã®åé¢è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¸ã®é©åˆåº¦ãŒä¸‹ãŒã‚‹ã€‚

### åˆ©ç‚¹ã¨æ¬ ç‚¹ã¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿

- åˆ©ç‚¹
    - ãƒ¢ãƒ‡ãƒ«ãŒç†è§£ã—ã‚„ã™ã„ã€‚
    - ã‚ã¾ã‚Šèª¿æ•´ã—ãªãã¦ã‚‚æ€§èƒ½ãŒå‡ºã‚„ã™ã„ã€‚
    - ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰ã¯é«˜é€Ÿ
- æ¬ ç‚¹
    - è¨“ç·´ã‚»ãƒƒãƒˆãŒå¤§ãããªã‚‹ã¨äºˆæ¸¬ãŒé…ããªã‚‹ã€‚
        - å®Ÿéš›ã«ä½¿ã†å‰ã«ã¯å‰å‡¦ç†ã‚’è¡Œã†ã“ã¨ãŒé‡è¦ã€‚
    - ç–ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ(ç‰¹å¾´é‡ã®å¤šããŒ0ã§ã‚ã‚‹)ã«å¯¾ã—ã¦ã¯ååˆ†ãªæ€§èƒ½ãŒå‡ºã«ãã„ã€‚

ä¸Šè¨˜ã®ç†ç”±ã‹ã‚‰ã€kNNã¯å®Ÿéš›ã«ä½¿ã‚ã‚Œã‚‹ã“ã¨ã¯å°‘ãªã„ã€‚

## ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 2 ç·šå½¢ãƒ¢ãƒ‡ãƒ«

### ç·šå½¢ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹å›å¸°

ç·šå½¢ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹äºˆæ¸¬å¼ã¯...

$$\hat{y} = w[0]\times x[0] + w[1]\times x[1] + ... + w[p]\times x[p] + b$$

- $\hat{y}$ã¯äºˆæ¸¬å€¤ã§ã€$w$ã¨$b$ã¯ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã€‚$x$ã¯ã‚ã‚‹ä¸€ã¤ã®ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆã®ç‰¹å¾´é‡ã€‚
- äºˆæ¸¬å€¤ã¯ã€ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆã‚’é©å½“ã«é‡ã¿ä»˜ã‘ã—ãŸã‚‚ã®ã€ã¨è¦‹ã‚‹ã“ã¨ã‚‚ã§ãã‚‹ã€‚

**wave**ã«ç·šå½¢å›å¸°ã‚’é©ç”¨ã—ã¦ãƒ—ãƒ­ãƒƒãƒˆã—ã¦ã¿ã‚ˆã†ã€‚


```python
mglearn.plots.plot_linear_regression_wave()
 ## w[0]: 0.393906  b: -0.031804
```

![](02_supervised_learning_files/figure-html/unnamed-chunk-26-1.png)<!-- -->

ç·šå½¢ãƒ¢ãƒ‡ãƒ«ã‚’åˆ©ç”¨ã—ãŸå›å¸°ã«ã¯ã„ã‚ã„ã‚ãªã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ãŒã‚ã£ã¦ã€ãã‚Œãã‚Œä»¥ä¸‹ã®ç‚¹ã§ç•°ãªã£ã¦ã„ã‚‹ã€‚

- ã©ã®ã‚ˆã†ã«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿$w$ã¨$b$ã‚’å­¦ç¿’ã™ã‚‹ã‹ã€‚
- ãƒ¢ãƒ‡ãƒ«ã®è¤‡é›‘ã•ã‚’ã©ã®ã‚ˆã†ã«åˆ¶å¾¡ã™ã‚‹ã®ã‹ã€‚

### ç·šå½¢å›å¸°(é€šå¸¸æœ€å°äºŒä¹—æ³•)

- äºˆæ¸¬å€¤ã¨çœŸå€¤ã®**å¹³å‡äºŒä¹—èª¤å·®** (mean squared error) ã‚’æœ€å°ã«ã™ã‚‹ã‚ˆã†ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ±‚ã‚ã‚‹ã€‚
- ç·šå½¢å›å¸°ã«ã¯è¤‡é›‘ã•ã‚’åˆ¶å¾¡ã™ã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒãªã„ã€‚ã§ããªã„ã€‚


```python
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
X, y = mglearn.datasets.make_wave(n_samples = 60)
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)
lr = LinearRegression().fit(X_train, y_train)
```

- $w$ã¯**ä¿‚æ•°** (coefficient)ã¨å‘¼ã°ã‚Œã€`coef_`ã«æ ¼ç´ã•ã‚Œã‚‹ã€‚
- $b$ã¯**åˆ‡ç‰‡** (intercept)ã¨å‘¼ã°ã‚Œã€`intercept_`ã«æ ¼ç´ã•ã‚Œã‚‹ã€‚


```python
print(lr.coef_)
 ## [0.39390555]
print(lr.intercept_)
 ## -0.03180434302675973
```

- è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å¾—ã‚‰ã‚ŒãŸå±æ€§ã«ã‚¢ãƒ³ãƒ€ãƒ¼ã‚¹ã‚³ã‚¢ã‚’ä»˜ã‘ã‚‹ã®ã¯**scikit-learn**ã®æ…£ç¿’ã§ã‚ã‚‹ã€‚
- `coef_`ã¯ç‰¹å¾´é‡1ã¤ã«å¯¾ã—ã¦1ã¤ã®å€¤ã‚’ã‚‚ã¤NumPyé…åˆ—ã¨ãªã‚‹ã€‚
- ç·šå½¢å›å¸°ã®æ€§èƒ½ã¯æ±ºå®šä¿‚æ•°$R^2$ã¨ã—ã¦æ±‚ã‚ã‚‰ã‚Œã‚‹ã€‚


```python
print(lr.score(X_train, y_train))
 ## 0.6700890315075756
print(lr.score(X_test, y_test))
 ## 0.6593368596863701
```

ã“ã“ã§è¨“ç·´ã‚»ãƒƒãƒˆã¨ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã®$R^2$ãŒã‚ã‚“ã¾ã‚Šé•ã‚ãªã„ã®ã¯ï¼ˆäºˆæ¸¬æ€§èƒ½ã¯ã¨ã‚‚ã‹ãï¼‰éå‰°é©åˆã—ã¦ã„ãªã„ã“ã¨ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚é€šå¸¸ã€ç‰¹å¾´é‡ãŒå¤šã„ã»ã©éå‰°é©åˆã®ãƒªã‚¹ã‚¯ãŒé«˜ã¾ã‚‹ã€‚æ‹¡å¼µã—ãŸ**boston_housing**ã§ç¢ºèªã—ã¦ã¿ã‚ˆã†ã€‚


```python
X, y = mglearn.datasets.load_extended_boston()
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)
lr = LinearRegression().fit(X_train, y_train)
```

$R^2$ã‚’è¨“ç·´ã‚»ãƒƒãƒˆã¨ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã§æ¯”è¼ƒã—ã¦ã¿ã‚ˆã†ã€‚


```python
print(lr.score(X_train, y_train))
 ## 0.9523526436864239
print(lr.score(X_test, y_test))
 ## 0.6057754892935757
```

ä¸¡è€…ã«ä¹–é›¢ãŒè¦‹ã‚‰ã‚Œã‚‹ã®ã¯ã€éå‰°é©åˆã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚

ãƒ¢ãƒ‡ãƒ«ã®è¤‡é›‘ã•ã‚’åˆ¶å¾¡ã§ãã‚Œã°è‰¯ã„ã®ã ãŒã€ç·šå½¢å›å¸°ã«ã¯ãã®ãŸã‚ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒãªã„ã€‚ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å°å…¥ã™ã‚‹æ–¹æ³•ã¨ã—ã¦**ãƒªãƒƒã‚¸å›å¸°**ãŒã‚ã‚‹ã€‚

### ãƒªãƒƒã‚¸å›å¸°

- ä¿‚æ•°ãŒå¤šã„ã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ãŒè¤‡é›‘ã«ãªã‚‹ã€‚
- ä¿‚æ•°ãŒ0ï¼ãã®ä¿‚æ•°ã‚’è€ƒæ…®ã—ãªã„ã€‚
- ä¿‚æ•°ãŒå°ã•ã‘ã‚Œã°ãƒ¢ãƒ‡ãƒ«ã¯å˜ç´”ã«ãªã‚‹ã®ã§ã¯ğŸ¤”
    - æ¥µç«¯ãªè©±ä¿‚æ•°ãŒå…¨éƒ¨ã‚¼ãƒ­ãªã‚‰å…¥åŠ›ã«é–¢ã‚ã‚‰ãšä¸€å®šã®å€¤(å¹³å‡ã¨ã‹)ã‚’å‡ºåŠ›ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã«ãªã‚‹ã€‚
- ä¿‚æ•°ãƒ™ã‚¯ãƒˆãƒ«ã®é•·ã•ã‚’æœ€å°åŒ–ã—ã‚ˆã†ï¼â†’ãƒªãƒƒã‚¸å›å¸°


```python
from sklearn.linear_model import Ridge
ridge = Ridge().fit(X_train, y_train) # ãƒ‡ãƒ¼ã‚¿ã¯æ‹¡å¼µBoston housingã®ã¾ã¾
print(ridge.score(X_train, y_train))
 ## 0.8860578560395836
print(ridge.score(X_test, y_test))
 ## 0.7527139600306947
```

- è¨“ç·´ã‚»ãƒƒãƒˆã¸ã®äºˆæ¸¬èƒ½åŠ›ãŒä¸‹ãŒã£ãŸã‘ã©ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã¸ã®äºˆæ¸¬èƒ½åŠ›ãŒä¸ŠãŒã£ãŸï¼
    - ãƒ¢ãƒ‡ãƒ«ã‚’å˜ç´”ã«ã™ã‚‹ã“ã¨ã§æ±åŒ–èƒ½åŠ›ãŒä¸ŠãŒã£ã¦ã„ã‚‹ã€‚
- ãƒªãƒƒã‚¸å›å¸°ã«ãŠã‘ã‚‹ãƒ¢ãƒ‡ãƒ«ã®å˜ç´”ã•ã‚’åˆ¶å¾¡ã™ã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: $\alpha$
    - å¤§ãã„ã»ã©åˆ¶ç´„ãŒå¼·ã„ = ãƒ¢ãƒ‡ãƒ«ãŒå˜ç´”ã«ãªã‚‹
    - sklearnã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯1.0
    - ä½•ãŒè‰¯ã„ã‹ã¯ãƒ‡ãƒ¼ã‚¿æ¬¡ç¬¬ã§ã€è‡ªå‹•çš„ã«ã¯èª¿æ•´ã•ã‚Œãªã„ï¼ˆå¾Œã§å¤šåˆ†ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ–¹æ³•ãŒå‡ºã¦æ¥ã‚‹ï¼‰ã€‚
    

```python
### alphaã‚’10å€ã«ã—ã¦ã¿ã‚‹ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆç”Ÿæˆæ™‚ã«æŒ‡å®š
ridge10 = Ridge(alpha = 10).fit(X_train, y_train)
print(ridge10.score(X_train, y_train))
 ## 0.7883461511233252
print(ridge10.score(X_test, y_test))
### alphaã‚’0.1å€ã«ã—ã¦ã¿ã‚‹ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆç”Ÿæˆæ™‚ã«æŒ‡å®š
 ## 0.6358967327447733
ridge01 = Ridge(alpha = .1).fit(X_train, y_train)
print(ridge01.score(X_train, y_train))
 ## 0.9285782082010734
print(ridge01.score(X_test, y_test))
 ## 0.7717933688844941
```

$\alpha$ã®å¤§ãã•ã¨ä¿‚æ•°ã®é–¢ä¿‚ã‚’ãƒ—ãƒ­ãƒƒãƒˆã—ã¦ã¿ã‚‹ã€‚$\alpha$ãŒå¤§ãã„ã»ã©ä¿‚æ•°ã®çµ¶å¯¾å€¤ã¯å°ã•ããªã‚‹ã¯ãšâ€¦


```python
plt.plot(ridge.coef_, 's', label="Ridge alpha=1")
plt.plot(ridge10.coef_, '^', label="Ridge alpha=10")
plt.plot(ridge01.coef_, 'v', label="Ridge alpha=0.1")
plt.plot(lr.coef_, 'o', label="LinearRegression")
plt.xlabel("ä¿‚æ•°ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹")
plt.ylabel("ä¿‚æ•°ã®å€¤")
plt.hlines(0, 0, len(lr.coef_))
plt.ylim(-25, 25)
plt.legend()
```

![](02_supervised_learning_files/figure-html/unnamed-chunk-35-1.png)<!-- -->

- ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã‚’å¢—ã‚„ã—ã¦ã„ãã¨ã‚¹ã‚³ã‚¢ã¯ã©ã®ã‚ˆã†ã«å¤‰åŒ–ã™ã‚‹ã‹ï¼Ÿ
    - **å­¦ç¿’æ›²ç·š** (learning curve): ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚µã‚¤ã‚ºã¨ã®é–¢ä¿‚ã§è¡¨ã—ãŸã‚‚ã®ã€‚
    - ãƒªãƒƒã‚¸å›å¸°ã¯æ­£å‰‡åŒ–ã®å½±éŸ¿ã§å¸¸ã«ç·šå½¢å›å¸°ã‚ˆã‚Šè¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¸ã®é©åˆãŒä½ã„ã€‚
    - ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã¸ã®é©åˆã¯ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚µã‚¤ã‚ºãŒå°ã•ã„ã†ã¡ã¯ãƒªãƒƒã‚¸å›å¸°ã®æ–¹ãŒå„ªã‚Œã‚‹ã€‚
    - ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚µã‚¤ã‚ºãŒå¤§ãããªã‚‹ã¨ã€ãƒªãƒƒã‚¸å›å¸°ã¨ç·šå½¢å›å¸°ã®å·®ã¯ãªããªã‚‹ã€‚
        - ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚µã‚¤ã‚ºãŒå¤§ãããªã‚‹ã¨ã€(å˜ç´”ãªãƒ¢ãƒ‡ãƒ«ã§ã¯)éå‰°é©åˆã™ã‚‹ã“ã¨ãŒé›£ã—ããªã‚‹ã€‚


```python
mglearn.plots.plot_ridge_n_samples()
plt.xlabel("è¨“ç·´ã‚»ãƒƒãƒˆã®ã‚µã‚¤ã‚º")
plt.ylabel("ã‚¹ã‚³ã‚¢(RÂ²)")
plt.legend(labels=["ãƒªãƒƒã‚¸ è¨“ç·´ã‚»ãƒƒãƒˆ", "ãƒªãƒƒã‚¸ ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆ", "ç·šå½¢å›å¸° è¨“ç·´ã‚»ãƒƒãƒˆ", "ç·šå½¢å›å¸° ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆ"])
```

![](02_supervised_learning_files/figure-html/unnamed-chunk-37-1.png)<!-- -->

### Lasso

- Ridgeã¨ã¯ç•°ãªã‚‹å½¢ã§ä¿‚æ•°ã«åˆ¶ç´„ã‚’ã‹ã‘ã‚‹ç·šå½¢å›å¸°ã€‚
    - L1æ­£å‰‡åŒ–: L1ãƒãƒ«ãƒ ã€ã¤ã¾ã‚Šä¿‚æ•°ã®çµ¶å¯¾å€¤ã®å’Œã«åˆ¶ç´„ã‚’ã‹ã‘ã‚‹ã€‚
- **ã„ãã¤ã‹ã®ä¿‚æ•°ãŒå®Œå…¨ã«0ã«ãªã‚‹å ´åˆãŒã‚ã‚‹**ã¨ã„ã†ç‚¹ãŒRidgeã¨å¤§ããç•°ãªã‚‹ã€‚
    - ä¿‚æ•°ãŒå®Œå…¨ã«0=ä¿‚æ•°ã‚’é™¤å¤–ã—ã¦ã„ã‚‹ã¨ã„ã†ã“ã¨ãªã®ã§ã€**è‡ªå‹•çš„ãªå¤‰æ•°é¸æŠ**ã¨ã‚‚ã¿ãªã›ã‚‹ã€‚
    - å¤‰æ•°ãŒæ¸›ã‚Œã°ãƒ¢ãƒ‡ãƒ«ã‚’è§£é‡ˆã—ã‚„ã™ããªã‚‹ã¨ã„ã†åˆ©ç‚¹ã‚‚ã‚ã‚‹ã€‚
    
Lassoã‚’**boston_housing**ã«é©ç”¨ã™ã‚‹ã€‚


```python
from sklearn.linear_model import Lasso
lasso = Lasso().fit(X_train, y_train)
print("è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚¹ã‚³ã‚¢: {:.2f}".format(lasso.score(X_train, y_train)))
 ## è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚¹ã‚³ã‚¢: 0.29
print("ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚¹ã‚³ã‚¢: {:.2f}".format(lasso.score(X_test, y_test)))
 ## ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚¹ã‚³ã‚¢: 0.21
print("é¸æŠã•ã‚ŒãŸç‰¹å¾´é‡æ•°: {}".format(np.sum(lasso.coef_ != 0)))
 ## é¸æŠã•ã‚ŒãŸç‰¹å¾´é‡æ•°: 4
```

- ã‚¹ã‚³ã‚¢ãŒéå¸¸ã«æ‚ªã„ã®ã¯ã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å…¨ããƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¦ã„ãªã„ã“ã¨ã«ã‚ˆã‚‹ã€‚
- Lassoã«ã¯è¤‡é›‘ã•ã®åº¦åˆã„ã‚’åˆ¶å¾¡ã™ã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿`alpha`ãŒã‚ã‚‹ã€‚`alpha`ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯1.0ã§ã€å°ã•ãã™ã‚‹ã»ã©è¤‡é›‘ãªãƒ¢ãƒ‡ãƒ«ã«ãªã‚‹ã€‚
- `alpha`ã‚’æ‰‹å‹•ã§æ¸›ã‚‰ã™éš›ã«ã¯ã€åˆã‚ã›ã¦`max_iter`ã‚’å¢—ã‚„ã—ã¦ã‚„ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚


```python
lasso001 = Lasso(alpha = 0.01, max_iter=100000).fit(X_train, y_train)
print("è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚¹ã‚³ã‚¢: {:.2f}".format(lasso001.score(X_train, y_train)))
 ## è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚¹ã‚³ã‚¢: 0.90
print("ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚¹ã‚³ã‚¢: {:.2f}".format(lasso001.score(X_test, y_test)))
 ## ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚¹ã‚³ã‚¢: 0.77
print("é¸æŠã•ã‚ŒãŸç‰¹å¾´é‡æ•°: {}".format(np.sum(lasso001.coef_ != 0)))
 ## é¸æŠã•ã‚ŒãŸç‰¹å¾´é‡æ•°: 33
```

- `alpha`ã‚’å°ã•ãã—ã™ãã‚‹ã¨éå‰°é©åˆã™ã‚‹ã€‚


```python
lasso00001 = Lasso(alpha = 0.0001, max_iter=100000).fit(X_train, y_train)
print("è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚¹ã‚³ã‚¢: {:.2f}".format(lasso00001.score(X_train, y_train)))
 ## è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚¹ã‚³ã‚¢: 0.95
print("ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚¹ã‚³ã‚¢: {:.2f}".format(lasso00001.score(X_test, y_test)))
 ## ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚¹ã‚³ã‚¢: 0.64
print("é¸æŠã•ã‚ŒãŸç‰¹å¾´é‡æ•°: {}".format(np.sum(lasso00001.coef_ != 0)))
 ## é¸æŠã•ã‚ŒãŸç‰¹å¾´é‡æ•°: 94
```


Ridgeã§ã‚„ã£ãŸã‚ˆã†ã«ä¿‚æ•°ã®å¤§ãã•ã‚’ãƒ—ãƒ­ãƒƒãƒˆã—ã¦ã¿ã‚ˆã†ã€‚


```python
plt.plot(lasso.coef_, 's', label = "Lasso alpha = 1")
plt.plot(lasso001.coef_, '^', label = "Lasso alpha = 0.01")
plt.plot(lasso00001.coef_, 'v', label = "Lasso alpha = 0.0001")
plt.plot(ridge01.coef_, 'o', label = "Ridge alpha = 0.1")
plt.legend(ncol = 2, loc = (0, 1.05))
plt.ylim = (-25, 25)
plt.xlabel("ä¿‚æ•°ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹")
plt.ylabel("ä¿‚æ•°ã®å¤§ãã•")
```

![](02_supervised_learning_files/figure-html/unnamed-chunk-42-1.png)<!-- -->

- åˆã‚ã›ã¦ãƒ—ãƒ­ãƒƒãƒˆã—ãŸRidge($\alpha=0.1$)ã¯ã€Lasso($\alpha=0.01$)ã¨åŒã˜ãã‚‰ã„ã®æ€§èƒ½ã§ã‚ã‚‹ãŒã€Ridgeã§ã¯å¤§ãã•ãŒå°ã•ã„ãªãŒã‚‰ã‚‚ä¿‚æ•°ã®å€¤ã¯0ã«ã¯ãªã£ã¦ã„ãªã„ã‚‚ã®ãŒå¤šã„ã®ã«å¯¾ã—ã¦ã€Lassoã§ã¯å¤§ãã•ãŒ0ã®ä¿‚æ•°ãŒç›®ç«‹ã¤ã€‚
- å®Ÿéš›ã«ã¯ã¾ãšRidgeã‚’è©¦ã™ã¨è‰¯ã„ã€‚
- ä¿‚æ•°ãŒãŸãã•ã‚“ã‚ã£ã¦é‡è¦ãªã®ã¯ãã®ã†ã¡ã®å¹¾ã¤ã‹å°‘æ•°ã§ã‚ã‚‹ã¨äºˆæƒ³ã•ã‚Œã‚‹ã®ã§ã‚ã‚Œã°ã€Lassoã‚’è©¦ã™ã¨è‰¯ã„ã€‚
- Ridgeã¨Lassoã®ãƒšãƒŠãƒ«ãƒ†ã‚£ã‚’çµ„åˆã›ãŸã‚‚ã®ã¨ã—ã¦ElasticNetãŒã‚ã‚‹ã€‚çµæœã¯è‰¯å¥½ã§ã‚ã‚‹ãŒã€ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã¹ããƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒå¢—ãˆã‚‹ã¨ã„ã†æ¬ ç‚¹ãŒã‚ã‚‹ã€‚

### ã‚¯ãƒ©ã‚¹åˆ†é¡ã®ãŸã‚ã®ç·šå½¢ãƒ¢ãƒ‡ãƒ«

ç·šå½¢ãƒ¢ãƒ‡ãƒ«ã§ã‚¯ãƒ©ã‚¹åˆ†é¡ã‚’è¡Œã†å ´åˆã¯ä»¥ä¸‹ã®å¼ã‚’ç”¨ã„ã‚‹ã€‚

$$\hat{y} = w[0]\times x[0] + w[1]\times x[1] + \dots + w[p]\times x[p] + b > 0$$

- å‡ºåŠ›$y$ãŒ0ã‚’è¶…ãˆã‚‹ã‹ã©ã†ã‹ã§åˆ¤åˆ¥ã™ã‚‹ã€‚
- å‡ºåŠ›$y$ã¯ç‰¹å¾´é‡ã®ç·šå½¢é–¢æ•°ã§ã‚ã‚Šã€2ã¤ã®ã‚¯ãƒ©ã‚¹ã‚’ç›´ç·šã‚„å¹³é¢ã€è¶…å¹³é¢ã§åˆ†å‰²ã™ã‚‹**æ±ºå®šå¢ƒç•Œ**ã¨ãªã‚‹ã€‚
- ç·šå½¢ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã™ã‚‹ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¯ä»¥ä¸‹ã®è¦³ç‚¹ã‹ã‚‰åˆ†é¡ã•ã‚Œã‚‹ã€‚
    - ã©ã®ã‚ˆã†ãªå°ºåº¦ã§è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¸ã®é©åˆåº¦ã‚’æ¸¬ã‚‹ã‹ã€‚
    - æ­£å‰‡åŒ–ã‚’è¡Œã†ã‹ã€‚è¡Œã†ãªã‚‰ã©ã®ã‚ˆã†ãªæ–¹æ³•ã‹ã€‚
- **ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°**ã¨**ç·šå½¢ã‚µãƒãƒ¼ãƒˆãƒ™ã‚¯ã‚¿ãƒ¼ãƒã‚·ãƒ³**ã¯ä¸€èˆ¬çš„ãªç·šå½¢ã‚¯ãƒ©ã‚¹ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã§ã‚ã‚‹ã€‚

**LogisticRegression**ã¨**LinearSVC**ã«ã‚ˆã‚Š**forge**ã‚’åˆ†é¡ã™ã‚‹æ±ºå®šå¢ƒç•Œã‚’å¯è¦–åŒ–ã™ã‚‹ã€‚


```python
from sklearn.linear_model import LogisticRegression
from sklearn.svm import LinearSVC
X, y = mglearn.datasets.make_forge()
fig, axes = plt.subplots(1, 2, figsize = (10, 3))
for model, ax in zip([LinearSVC(), LogisticRegression()], axes):
  clf = model.fit(X, y)
  mglearn.plots.plot_2d_separator(clf, X, fill = False, eps = 0.5, ax = ax, alpha = 0.7)
  mglearn.discrete_scatter(X[:, 0], X[:, 1], y, ax = ax)
  ax.set_title("{}".format(clf.__class__.__name__))
  ax.set_xlabel("ç‰¹å¾´é‡ 0")
  ax.set_ylabel("ç‰¹å¾´é‡ 1")
  
axes[0].legend()
```

![](02_supervised_learning_files/figure-html/unnamed-chunk-44-1.png)<!-- -->

- 2ã¤ã®ã‚¯ãƒ©ã‚¹åˆ†é¡å™¨ã¯ã„ãšã‚Œã‚‚æ­£å‰‡åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿Cã‚’æŒã¤ã€‚Cã¯å¤§ãã„ã»ã©æ­£å‰‡åŒ–ãŒå¼±ããªã‚‹ã€‚
- CãŒã¯å°ã•ã„ã¨ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆã®å¤šæ•°æ´¾ã«é©åˆã—ã‚ˆã†ã¨ã™ã‚‹ãŒã€å¤§ããã™ã‚‹ã¨å€‹ã€…ã®ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆã‚’æ­£ç¢ºã«åˆ†é¡ã—ã‚ˆã†ã¨ã™ã‚‹ã€‚


```python
mglearn.plots.plot_linear_svc_regularization()
```

![](02_supervised_learning_files/figure-html/unnamed-chunk-46-1.png)<!-- -->

- ä¸Šè¨˜ã®ä¾‹ã§ã¯ã€Cã‚’å¤§ããã™ã‚‹ã¨èª¤åˆ†é¡ã—ãŸå°‘æ•°ã®ç‚¹ã«æ±ºå®šå¢ƒç•ŒãŒå¤§ããå½±éŸ¿ã•ã‚Œã¦ã„ã‚‹ã“ã¨ãŒã‚ã‹ã‚‹ã€‚
- ä½æ¬¡å…ƒã®å ´åˆã¯ç·šå½¢åˆ†é¡ã¯åˆ¶ç´„ãŒå¼·ã„ã‚ˆã†ã«æ€ãˆã‚‹ãŒã€æ¬¡å…ƒæ•°ãŒå¤§ãããªã‚‹ã¨ãƒ¢ãƒ‡ãƒ«ã¯å¼·åŠ›ã«ãªã‚Šã€ã‚€ã—ã‚éå‰°é©åˆã‚’ã„ã‹ã«é¿ã‘ã‚‹ã‹ãŒãƒã‚¤ãƒ³ãƒˆã«ãªã‚‹ã€‚

**cancer**ã«**LogisticRegression**ã‚’é©ç”¨ã—ã¦ã¿ã‚‹ã€‚


```python
from sklearn.datasets import load_breast_cancer
cancer = load_breast_cancer()
X_train, X_test, y_train, y_test = train_test_split(
  cancer.data, cancer.target, stratify = cancer.target, random_state = 42
)
logreg = LogisticRegression().fit(X_train, y_train)
print("ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã‚¹ã‚³ã‚¢: {:.3f}".format(logreg.score(X_train, y_train)))
 ## ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã‚¹ã‚³ã‚¢: 0.953
print("è¨“ç·´ã‚»ãƒƒãƒˆã‚¹ã‚³ã‚¢: {:.3f}".format(logreg.score(X_test, y_test)))
 ## è¨“ç·´ã‚»ãƒƒãƒˆã‚¹ã‚³ã‚¢: 0.958
```

- **è¨“ç·´ã‚»ãƒƒãƒˆã¨ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã®ã‚¹ã‚³ã‚¢ãŒè¿‘ã„å ´åˆã¯é©åˆä¸è¶³ã‚’ç–‘ã†ã€‚**

ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿Cã‚’å¤§ããã—ã¦ãƒ¢ãƒ‡ãƒ«ã®è¤‡é›‘ã•ã‚’ä¸Šã’ã‚‹ã€‚


```python
logreg100 = LogisticRegression(C=100).fit(X_train, y_train)
print("ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã‚¹ã‚³ã‚¢: {:.3f}".format(logreg100.score(X_train, y_train)))
 ## ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã‚¹ã‚³ã‚¢: 0.967
print("è¨“ç·´ã‚»ãƒƒãƒˆã‚¹ã‚³ã‚¢: {:.3f}".format(logreg100.score(X_test, y_test)))
 ## è¨“ç·´ã‚»ãƒƒãƒˆã‚¹ã‚³ã‚¢: 0.965
```

ç²¾åº¦ãŒä¸ŠãŒã£ãŸã€‚ä»Šåº¦ã¯é€†ã«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿Cã‚’å°ã•ãã—ã¦ã¿ã‚‹ã€‚


```python
logreg001 = LogisticRegression(C=0.01).fit(X_train, y_train)
print("ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã‚¹ã‚³ã‚¢: {:.3f}".format(logreg001.score(X_train, y_train)))
 ## ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã‚¹ã‚³ã‚¢: 0.934
print("è¨“ç·´ã‚»ãƒƒãƒˆã‚¹ã‚³ã‚¢: {:.3f}".format(logreg001.score(X_test, y_test)))
 ## è¨“ç·´ã‚»ãƒƒãƒˆã‚¹ã‚³ã‚¢: 0.930
```

ç²¾åº¦ãŒä¸‹ãŒã£ãŸã€‚æœ€å¾Œã«ã€3ã¤ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã«ã¤ã„ã¦ä¿‚æ•°ã‚’å¯è¦–åŒ–ã—ã¦ã¿ã‚‹ã€‚


```python
plt.plot(logreg.coef_.T, 'o', label = "C=1")
plt.plot(logreg100.coef_.T, '^', label = "C=100")
plt.plot(logreg001.coef_.T, 'v', label = "C=0.01")
plt.xticks(range(cancer.data.shape[1]), cancer.feature_names, rotation=90)
plt.hlines(0, 0, cancer.data.shape[1])
plt.xlabel("ç‰¹å¾´é‡")
plt.ylabel("ä¿‚æ•°ã®å¤§ãã•")
plt.legend()
```

![](02_supervised_learning_files/figure-html/unnamed-chunk-51-1.png)<!-- -->

- ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã¯**LogisticRegression**ã¯L2æ­£å‰‡åŒ–ã‚’è¡Œã†ã€‚
- `penalty="l1"`ã®æŒ‡å®šã§L1æ­£å‰‡åŒ–ã«åˆ‡ã‚Šæ›¿ãˆã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚ã‚ˆã‚Šå˜ç´”ãªãƒ¢ãƒ‡ãƒ«ãŒæ¬²ã—ã‘ã‚Œã°ã“ã¡ã‚‰ã‚’è©¦ã™ã¨è‰¯ã„ã€‚


```python
for C, marker in zip([0.001, 1, 100], ['o', '^', 'v']):
  lr_l1 = LogisticRegression(C = C, penalty = "l1").fit(X_train, y_train)
  print("è¨“ç·´ã‚»ãƒƒãƒˆã«å¯¾ã™ã‚‹ç²¾åº¦(C={:.3f}): {:.2f}".format(C, lr_l1.score(X_train, y_train)))
  print("ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã«å¯¾ã™ã‚‹ç²¾åº¦(C={:.3f}): {:.2f}".format(C, lr_l1.score(X_test, y_test)))
  plt.plot(lr_l1.coef_.T, marker, label = "C={:.3f}".format(C))
 ## è¨“ç·´ã‚»ãƒƒãƒˆã«å¯¾ã™ã‚‹ç²¾åº¦(C=0.001): 0.91
 ## ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã«å¯¾ã™ã‚‹ç²¾åº¦(C=0.001): 0.92
 ## è¨“ç·´ã‚»ãƒƒãƒˆã«å¯¾ã™ã‚‹ç²¾åº¦(C=1.000): 0.96
 ## ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã«å¯¾ã™ã‚‹ç²¾åº¦(C=1.000): 0.96
 ## è¨“ç·´ã‚»ãƒƒãƒˆã«å¯¾ã™ã‚‹ç²¾åº¦(C=100.000): 0.99
 ## ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã«å¯¾ã™ã‚‹ç²¾åº¦(C=100.000): 0.98
plt.xticks(range(cancer.data.shape[1]), cancer.feature_names, rotation = 90)
plt.hlines(0, 0, cancer.data.shape[1])
plt.xlabel("ç‰¹å¾´é‡")
plt.ylabel("ä¿‚æ•°ã®å¤§ãã•")
plt.legend(loc = 3)
```

![](02_supervised_learning_files/figure-html/unnamed-chunk-53-1.png)<!-- -->

### ç·šå½¢ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹å¤šã‚¯ãƒ©ã‚¹åˆ†é¡

- å¤§æŠµã®ç·šå½¢ã‚¯ãƒ©ã‚¹åˆ†é¡ã¯2ã‚¯ãƒ©ã‚¹åˆ†é¡ã«ã—ã‹å¯¾å¿œã—ã¦ãŠã‚‰ãšã€ãã®ã¾ã¾ã§ã¯å¤šã‚¯ãƒ©ã‚¹ã«æ‹¡å¼µã™ã‚‹ã“ã¨ã¯ã§ããªã„ã€‚
    - ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ã¯ä¾‹å¤–
- æ‹¡å¼µã™ã‚‹ãŸã‚ã®æ–¹æ³•ã¨ã—ã¦**1å¯¾ãã®ä»–(one-vs.-rest)**ã‚¢ãƒ—ãƒ­ãƒ¼ãƒãŒã‚ã‚‹ã€‚
    - **1ã¤ã®ã‚¯ãƒ©ã‚¹ã¨ãã®ä»–ã®ã‚¯ãƒ©ã‚¹**ã¨ã„ã†2ã‚¯ãƒ©ã‚¹åˆ†é¡ã«å¯¾ã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã•ã›ã‚‹ã€‚
    - ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆã«å¯¾ã—ã¦ã¯å…¨ã¦ã®2ã‚¯ãƒ©ã‚¹åˆ†é¡ã‚’å®Ÿè¡Œã™ã‚‹ã€‚
    - **ä¸€ç•ªé«˜ã„ã‚¹ã‚³ã‚¢ã®ã‚¯ãƒ©ã‚¹åˆ†é¡å™¨**ã®åˆ†é¡çµæœã‚’äºˆæ¸¬çµæœã¨ã™ã‚‹ã€‚
    - ã‚¯ãƒ©ã‚¹ã”ã¨ã«2ã‚¯ãƒ©ã‚¹åˆ†é¡ãŒå­˜åœ¨ã™ã‚‹ã¨ã„ã†ã“ã¨ãªã®ã§ã€ã‚¯ãƒ©ã‚¹ã”ã¨ã«ä»¥ä¸‹ã®å¼ã§è¡¨ã™ç¢ºä¿¡åº¦ãŒå­˜åœ¨ã—ã€ç¢ºä¿¡åº¦ãŒæœ€ã‚‚å¤§ãã„ã‚¯ãƒ©ã‚¹ãŒã‚¯ãƒ©ã‚¹ãƒ©ãƒ™ãƒ«ã¨ãªã‚‹ã€‚
    
$$ w[0] \times x[0] + w[1] \times x[1] + \dots + w[p] \times x[p] + b$$

- å¤šã‚¯ãƒ©ã‚¹ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ã¨1å¯¾å¤šã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯å¤šå°‘ç•°ãªã‚‹ãŒã€1ã‚¯ãƒ©ã‚¹ã‚ãŸã‚Šä¿‚æ•°ãƒ™ã‚¯ãƒˆãƒ«ã¨åˆ‡ç‰‡ãŒã§ãã‚‹ã¨ã„ã†ç‚¹ã¯å…±é€šã—ã¦ã„ã‚‹ã€‚

3ã‚¯ãƒ©ã‚¹åˆ†é¡ã«å¯¾ã—ã¦1å¯¾å¤šã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’è©¦ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã¯ã‚¬ã‚¦ã‚¹åˆ†å¸ƒã‹ã‚‰ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ãŸ2æ¬¡å…ƒãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨ã™ã‚‹ã€‚


```python
from sklearn.datasets import make_blobs
X, y = make_blobs(random_state = 42)
mglearn.discrete_scatter(X[:, 0], X[:, 1], y)
plt.xlabel("ç‰¹å¾´é‡0")
plt.ylabel("ç‰¹å¾´é‡1")
plt.legend(["ã‚¯ãƒ©ã‚¹0", "ã‚¯ãƒ©ã‚¹1", "ã‚¯ãƒ©ã‚¹2"])
```

![](02_supervised_learning_files/figure-html/unnamed-chunk-55-1.png)<!-- -->

ã“ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§**LinearSVC**ã‚’å­¦ç¿’ã•ã›ã‚‹ã€‚


```python
linear_svm = LinearSVC().fit(X, y)
print("ä¿‚æ•°ãƒ™ã‚¯ãƒˆãƒ«ã®å½¢çŠ¶", linear_svm.coef_.shape)
 ## ä¿‚æ•°ãƒ™ã‚¯ãƒˆãƒ«ã®å½¢çŠ¶ (3, 2)
print("åˆ‡ç‰‡ãƒ™ã‚¯ãƒˆãƒ«ã®å½¢çŠ¶", linear_svm.intercept_.shape)
 ## åˆ‡ç‰‡ãƒ™ã‚¯ãƒˆãƒ«ã®å½¢çŠ¶ (3,)
```

- ä¿‚æ•°ãƒ™ã‚¯ãƒˆãƒ«ã®å½¢çŠ¶ãŒ3è¡Œ2åˆ—ã¨ã„ã†ã“ã¨ã¯ã€å„è¡Œã«å„ã‚¯ãƒ©ã‚¹ã«å¯¾å¿œã™ã‚‹2æ¬¡å…ƒã®ä¿‚æ•°ãƒ™ã‚¯ãƒˆãƒ«ãŒæ ¼ç´ã•ã‚Œã¦ã„ã‚‹ã¨ã„ã†ã“ã¨ã§ã‚ã‚‹ã€‚
- åˆ‡ç‰‡ãƒ™ã‚¯ãƒˆãƒ«ã¯ã‚¯ãƒ©ã‚¹ã®æ•°ã«å¯¾å¿œã—ã¦ã„ã‚‹ã€‚
- ä¸Šè¨˜2ç‚¹ã‚’ã¾ã¨ã‚ã‚‹ã¨ã€3ã¤ã®ã‚¯ãƒ©ã‚¹åˆ†é¡å™¨ãŒå¾—ã‚‰ã‚Œã¦ã„ã‚‹ã¨ã„ã†ã“ã¨ã§ã‚ã‚‹ã€‚

3ã¤ã®ã‚¯ãƒ©ã‚¹åˆ†é¡å™¨ãŒä½œã‚‹æ±ºå®šå¢ƒç•Œã‚’å¯è¦–åŒ–ã™ã‚‹ã€‚


```python
mglearn.discrete_scatter(X[:, 0], X[:, 1], y)
line = np.linspace(-15, 15)
for coef, intercept, color in zip(linear_svm.coef_, linear_svm.intercept_, ['b', 'r', 'g']):
  plt.plot(line, -(line * coef[0] + intercept) / coef[1], c = color)
plt.xlabel("ç‰¹å¾´é‡0")
plt.ylabel("ç‰¹å¾´é‡1")
plt.legend(['ã‚¯ãƒ©ã‚¹0', 'ã‚¯ãƒ©ã‚¹1', 'ã‚¯ãƒ©ã‚¹2', 'ã‚¯ãƒ©ã‚¹0ã®æ±ºå®šå¢ƒç•Œ', 'ã‚¯ãƒ©ã‚¹1ã®æ±ºå®šå¢ƒç•Œ', 'ã‚¯ãƒ©ã‚¹2ã®æ±ºå®šå¢ƒç•Œ'],
  loc = (1.01, 0.3))
```

![](02_supervised_learning_files/figure-html/unnamed-chunk-58-1.png)<!-- -->

- æ±ºå®šå¢ƒç•ŒãŒä½œã‚‹é ˜åŸŸã®ä¸­ã«ã¯è¤‡æ•°ã®ã‚¯ãƒ©ã‚¹ãŒå±ã™ã‚‹éƒ¨åˆ†(å·¦ã€å³ä¸Šã€å³ä¸‹ã®ä¸‰è§’å½¢é ˜åŸŸ)ã¨ã€ã™ã¹ã¦ã®ã‚¯ãƒ©ã‚¹ãŒå±ã•ãªã„éƒ¨åˆ†(ä¸­å¤®ã®ä¸‰è§’)ãŒã‚ã‚‹ã€‚ã“ã®å†…éƒ¨ã§ã¯ã€**ã‚¯ãƒ©ã‚¹åˆ†é¡å¼ã®å€¤ãŒä¸€ç•ªå¤§ãã„ã‚¯ãƒ©ã‚¹**ãŒäºˆæ¸¬ã•ã‚Œã‚‹ã‚¯ãƒ©ã‚¹ã¨ãªã‚‹ã€‚
- ä¾‹ãˆã°ã€ä¸­å¤®ã®ä¸‰è§’ã§ã‚ã‚Œã°å¯¾å¿œã™ã‚‹æ±ºå®šå¢ƒç•ŒãŒæœ€ã‚‚è¿‘ã„ã‚¯ãƒ©ã‚¹ã«åˆ†é¡ã•ã‚Œã‚‹ã€‚

ä¸Šè¨˜ã®ãƒ«ãƒ¼ãƒ«ã«å¾“ã£ã¦ã€å¤šã‚¯ãƒ©ã‚¹åˆ†é¡ã«ãŠã‘ã‚‹æœ€çµ‚çš„ãªæ±ºå®šå¢ƒç•Œã‚’ç¤ºã™ã€‚


```python
mglearn.plots.plot_2d_classification(linear_svm, X, fill = True, alpha = .7)
mglearn.discrete_scatter(X[:, 0], X[:, 1], y)
line = np.linspace(-15, 15)
for coef, intercept, color in zip(linear_svm.coef_, linear_svm.intercept_, ['b', 'r', 'g']):
  plt.plot(line, -(line * coef[0] + intercept) / coef[1], c = color)
plt.legend(["ã‚¯ãƒ©ã‚¹0", "ã‚¯ãƒ©ã‚¹1", "ã‚¯ãƒ©ã‚¹2", "ã‚¯ãƒ©ã‚¹0ã®æ±ºå®šå¢ƒç•Œ", "ã‚¯ãƒ©ã‚¹1ã®æ±ºå®šå¢ƒç•Œ", "ã‚¯ãƒ©ã‚¹2ã®æ±ºå®šå¢ƒç•Œ"],
  loc = (1.01, 0.3))
plt.xlabel("ç‰¹å¾´é‡0")
plt.ylabel("ç‰¹å¾´é‡1")
```

![](02_supervised_learning_files/figure-html/unnamed-chunk-60-1.png)<!-- -->

### åˆ©ç‚¹ã€æ¬ ç‚¹ã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿

- ç·šå½¢ãƒ¢ãƒ‡ãƒ«ã®ä¸»è¦ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    - å›å¸°ãƒ¢ãƒ‡ãƒ«: alpha
        - å¤§ãã„ã¨å˜ç´”ãªãƒ¢ãƒ‡ãƒ«
    - LinearSVCã¨LogisticRegression: C
        - å°ã•ã„ã¨å˜ç´”ãªãƒ¢ãƒ‡ãƒ«
- alphaã€Cã¯å¯¾æ•°ã‚¹ã‚±ãƒ¼ãƒ«ã§èª¿æ•´ã™ã‚‹ã€‚
- æ­£å‰‡åŒ–ã‚’è¡Œã†å ´åˆã¯L1ã‹L2ã‹ã‚‚é‡è¦ãªãƒã‚¤ãƒ³ãƒˆã€‚
    - ä¸€éƒ¨ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒé‡è¦ã¨äºˆæƒ³ã•ã‚Œã‚‹: L1
        - ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’é™å®šã§ãã‚‹ã®ã§ã€ãƒ¢ãƒ‡ãƒ«ã‚’èª¬æ˜ã—ã‚„ã™ããªã‚‹ã€‚
    - ç‰¹ã«ãã®ã‚ˆã†ãªã“ã ã‚ã‚ŠãŒãªã„: L2
- ç·šå½¢ãƒ¢ãƒ‡ãƒ«ã®åˆ©ç‚¹
    - è¨“ç·´ã€äºˆæ¸¬ã¨ã‚‚ã«é«˜é€Ÿã€‚
    - å¤§ããªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã‚‚ç–ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã‚‚ä¸Šæ‰‹ãå‹•ãã€‚
    - éå¸¸ã«å¤§ããªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¸ã®å¯¾å‡¦ã¯2é€šã‚Šã‚ã‚‹ã€‚
        - LogisticRegressionã¨Ridgeã«`solver='sag'`ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’æŒ‡å®šã™ã‚‹ã€‚
        - SGDClassifierã‚¯ãƒ©ã‚¹ã¨SGDRegressorã‚¯ãƒ©ã‚¹ã®åˆ©ç”¨ã‚’æ¤œè¨ã™ã‚‹ã€‚
- ç·šå½¢ãƒ¢ãƒ‡ãƒ«ã®æ¬ ç‚¹
    - äºˆæ¸¬æ‰‹æ³•ã¯ç†è§£ã—ã‚„ã™ã„åé¢ã€ä¿‚æ•°ãŒãªãœãã®å€¤ã«ãªã£ã¦ã„ã‚‹ã®ã‹ã¯å¿…ãšã—ã‚‚è‡ªæ˜ã§ã¯ãªã„ã€‚
        - ç‰¹ã«ä¿‚æ•°é–“ã«ç›¸é–¢ãŒã‚ã‚‹å ´åˆã€‚
        
## ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 3 ãƒŠã‚¤ãƒ¼ãƒ–ãƒ™ã‚¤ã‚ºã‚¯ãƒ©ã‚¹åˆ†é¡å™¨

- ç·šå½¢ãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šã•ã‚‰ã«é«˜é€Ÿã«è¨“ç·´ãŒã§ãã‚‹ã€‚
    - æ±åŒ–æ€§èƒ½ã¯åŠ£ã‚‹å ´åˆãŒã‚ã‚‹ã€‚
- scikit-learnã«å®Ÿè£…ã•ã‚Œã¦ã„ã‚‹ãƒŠã‚¤ãƒ¼ãƒ–ãƒ™ã‚¤ã‚ºã‚¯ãƒ©ã‚¹åˆ†é¡å™¨ã¯3ç¨®ã€‚
    - GaussianNB: ä»»æ„ã®é€£ç¶šå€¤ãƒ‡ãƒ¼ã‚¿ã«é©ç”¨ã§ãã‚‹ã€‚
    - BernoulliNB: 2å€¤ãƒ‡ãƒ¼ã‚¿ã‚’ä»®å®šã—ã¦ã„ã‚‹ã€‚
    - MultinomialNB: ã‚«ã‚¦ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’ä»®å®šã—ã¦ã„ã‚‹ã€‚
        - ã‚«ã‚¦ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿...æ–‡ç« ä¸­ã®å˜èªã®å‡ºç¾å›æ•°ãªã©ã€å€‹ã€…ã®ç‰¹å¾´é‡ã®å€¤ãŒä½•ã‹ã®ã‚«ã‚¦ãƒ³ãƒˆã§ã‚ã‚‹ã‚‚ã®ã€‚
- BernoulliNBã¯ç‰¹å¾´é‡æ¯ã«éã‚¼ãƒ­ã®å ´åˆã‚’ã‚«ã‚¦ãƒ³ãƒˆã™ã‚‹ã€‚


```python
import numpy as np
X = np.array([[0, 1, 0, 1],
              [1, 0, 1, 1],
              [0, 0, 0, 1],
              [1, 0, 1, 0]])
y = np.array([0, 1, 0, 1])
counts = {}
for label in np.unique(y):
  counts[label] = X[y == label].sum(axis=0)
print("éã‚¼ãƒ­ã®ç‰¹å¾´é‡ã®ã‚«ã‚¦ãƒ³ãƒˆ:\n{}".format(counts))
 ## éã‚¼ãƒ­ã®ç‰¹å¾´é‡ã®ã‚«ã‚¦ãƒ³ãƒˆ:
 ## {0: array([0, 1, 0, 2]), 1: array([2, 0, 2, 1])}
```

- MultinominalNBã¯ã‚¯ãƒ©ã‚¹ã”ã¨ã®å€‹ã€…ã®ç‰¹å¾´é‡ã®å¹³å‡å€¤ã‚’è€ƒæ…®ã«å…¥ã‚Œã‚‹ã€‚
- GaussianNBã¯å¹³å‡å€¤ã«åŠ ãˆã¦æ¨™æº–åå·®ã‚‚è€ƒæ…®ã™ã‚‹ã€‚
- äºˆæ¸¬å¼ã®å½¢ã¯ç·šå½¢ãƒ¢ãƒ‡ãƒ«ã¨åŒã˜ã«ãªã‚‹ãŒã€`coef_`ã¯$w$ã¨ã¯è‹¥å¹²æ„å‘³ãŒç•°ãªã‚‹ã€‚

### åˆ©ç‚¹ã€æ¬ ç‚¹ã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿

- MultinomialNBã¨BernoulliNBã¯å”¯ä¸€ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨ã—ã¦alphaã‚’æŒã¤ã€‚
- alphaã‚’å¤§ããã™ã‚‹ã¨ãƒ¢ãƒ‡ãƒ«ã®è¤‡é›‘ã•ãŒæ¸›ã‚‹ãŒã€alphaã‚’å¤‰åŒ–ã•ã›ã¦ã‚‚ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®æ€§èƒ½ã¯ãã‚Œã»ã©å¤‰åŒ–ã—ãªã„ã€‚ã—ã‹ã—ã€å ´åˆã«ã‚ˆã£ã¦ã¯ç²¾åº¦ã‚’å¤šå°‘ä¸Šã’ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚
- GaussianNBã¯é«˜æ¬¡å…ƒãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦ç”¨ã„ã‚‹å ´åˆãŒå¤šã„ã€‚
- MultinomialNBã¯BernoulliNBã‚ˆã‚Šè‹¥å¹²æ€§èƒ½ãŒè‰¯ãã€ç‰¹ã«éã‚¼ãƒ­ç‰¹å¾´é‡ãŒå¤šæ•°ã‚ã‚‹å ´åˆã«å¼·ã„ã€‚

## ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 4 æ±ºå®šæœ¨

- ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®ãŸã‚ã«ã¯graphvizã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãŠãå¿…è¦ãŒã‚ã‚‹ã€‚
    - `pip install graphviz`ä»¥å¤–ã«ã€åˆ¥é€”OSã«å¿œã˜ãŸæ–¹æ³•ã§graphvizã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã€‚
    - ubuntuãªã‚‰ã°`sudo apt-get install graphviz`ã€‚
- å›å¸°ã«ã‚‚åˆ†é¡ã«ã‚‚ä½¿ãˆã‚‹ã€‚
- Yes/Noã§ç­”ãˆã‚‰ã‚Œã‚‹è³ªå•ã§å‡ºæ¥ãŸ**æœ¨**ã‚’æ§‹æˆã™ã‚‹ã€‚


```python
mglearn.plots.plot_animal_tree()
```

![](02_supervised_learning_files/figure-html/unnamed-chunk-63-1.png)<!-- -->


### æ±ºå®šæœ¨ã®æ§‹ç¯‰

- 2ã¤ã®ç‰¹å¾´é‡ã€2ã¤ã®ã‚¯ãƒ©ã‚¹ã‚’æŒã¤ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆtwo_moonã‚’ä½¿ç”¨ã™ã‚‹ã€‚
    - 2ã¤ã®ç‰¹å¾´é‡ã®ãªã™å¹³é¢ä¸Šã§2ã¤ã®ã‚¯ãƒ©ã‚¹ãŒåŠæœˆã‚’çµ„åˆã›ãŸã‚ˆã†ã«åˆ†å¸ƒã—ã¦ã„ã‚‹ã€‚


```python
from sklearn.datasets import make_moons
from mglearn.tools import discrete_scatter
X, y = make_moons(n_samples=100, noise=0.25, random_state=3)
plt.figure()
ax = plt.gca()
discrete_scatter(X[:, 0], X[:, 1], y, ax=ax)
ax.set_xticks(())
ax.set_yticks(())
```

![](02_supervised_learning_files/figure-html/unnamed-chunk-65-1.png)<!-- -->

- æœ¨ã®æ§‹ç¯‰ã¯ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®åˆ†å‰²ã®ç¹°ã‚Šè¿”ã—ã§ã‚ã‚‹ã€‚åˆ†å‰²ã•ã‚ŒãŸéƒ¨åˆ†ã‚’**è‘‰**ã¨å‘¼ã¶ã€‚
- åˆ†å‰²ã«ã‚ˆã‚Šãƒ†ã‚¹ãƒˆãŒ1æ®µéšå¢—ãˆã‚‹(e.g. X[1]ã¯0.06ä»¥ä¸Šã§ã‚ã‚‹ã‹ï¼Ÿ)
- å„ã‚¹ãƒ†ãƒƒãƒ—ã§åˆ†å‰²ã¯æƒ…å ±é‡ãŒæœ€ã‚‚å¤šããªã‚‹ã‚ˆã†ã«ï¼ˆæœ€ã‚‚ã‚¯ãƒ©ã‚¹ã‚’åˆ†å‰²ã™ã‚‹ã‚ˆã†ã«ï¼‰è¡Œã‚ã‚Œã‚‹ã€‚
- åˆ†å‰²ã¯ãƒ†ã‚¹ãƒˆã«ã‚ˆã£ã¦ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒå®Œå…¨ã«åˆ†é¡ã§ãã‚‹ã‚ˆã†ã«ãªã‚‹ã¾ã§é€²ã‚€ã€‚
- 1ã¤ã®è‘‰ã«1ç¨®é¡ã®ã‚¯ãƒ©ã‚¹ã‚„å€¤ã—ã‹å«ã¾ãªã„çŠ¶æ…‹ã«ãªã£ãŸæœ¨ã‚’**ç´”ç²‹**(pure)ã¨å‘¼ã¶ã€‚

ä»¥ä¸‹ã«two_moonã‹ã‚‰ç´”ç²‹ãªæ±ºå®šæœ¨ã‚’ä½œæˆã™ã‚‹éç¨‹ã‚’ç¤ºã™ã€‚


```python
for i, max_depth in enumerate([1, 2, 9]):
  fig, ax = plt.subplots(1, 2, figsize = (12, 4), subplot_kw={'xticks': (), 'yticks': ()})
  tree = mglearn.plot_interactive_tree.plot_tree(X, y, max_depth = max_depth, ax = ax[0])
  ax[1].imshow(mglearn.plot_interactive_tree.tree_image(tree))
  plt.show()
  plt.close()
```

![](02_supervised_learning_files/figure-html/unnamed-chunk-66-1.png)<!-- -->![](02_supervised_learning_files/figure-html/unnamed-chunk-66-2.png)<!-- -->![](02_supervised_learning_files/figure-html/unnamed-chunk-66-3.png)<!-- -->

æ±ºå®šæœ¨ã¯ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãŒã‚¯ãƒ©ã‚¹ã§ã¯ãªãé€£ç¶šå€¤ã«ãªã£ã¦ã‚‚åŒã˜ã‚ˆã†ã«æ©Ÿèƒ½ã™ã‚‹ã®ã§ã€å›å¸°ã«ã‚‚ä½¿ãˆã‚‹ã€‚

### æ±ºå®šæœ¨ã®è¤‡é›‘ã•ã®åˆ¶å¾¡

- ç´”ç²‹ã«ãªã‚‹ã¾ã§åˆ†å‰²ã‚’ç¶šã‘ã‚‹ã¨ãƒ«ãƒ¼ãƒ«ãŒè¤‡é›‘ã«ãªã‚Šã™ãã€å®¹æ˜“ã«éå‰°é©åˆã—ã¦ã—ã¾ã†ã€‚
- éå‰°é©åˆã‚’é˜²ãæˆ¦ç•¥ã¯2ã¤ã‚ã‚‹ã€‚
    - äº‹å‰æåˆˆã‚Š: æ§‹ç¯‰éç¨‹ã§æœ¨ã®ç”Ÿæˆã‚’æ­¢ã‚ã‚‹ã€‚å˜ã«æåˆˆã‚Šã¨ã‚‚ã€‚
        - æœ¨ã®æ·±ã•ã‚’åˆ¶é™ã™ã‚‹æ–¹æ³•ã€è‘‰ã®æœ€å¤§å€¤ã‚’åˆ¶é™ã™ã‚‹æ–¹æ³•ã€è‘‰ã«å«ã¾ã‚Œã‚‹ãƒ‡ãƒ¼ã‚¿ç‚¹ã®æœ€å°æ•°ã‚’åˆ¶é™ã™ã‚‹æ–¹æ³•ãŒã‚ã‚‹ã€‚
        - scikit-learnã«ã¯äº‹å‰æåˆˆã‚Šã—ã‹å®Ÿè£…ã•ã‚Œã¦ã„ãªã„ã€‚
    - äº‹å¾Œæåˆˆã‚Š: æœ¨ã‚’æ§‹ç¯‰ã—ã¦ã‹ã‚‰æƒ…å ±é‡ã®å°‘ãªã„æã‚’å‰Šé™¤ã™ã‚‹ã€‚
- scikit-learnã®æ±ºå®šæœ¨ã®å®Ÿè£…
    - å›å¸°: DecisionTreeRegressorã‚¯ãƒ©ã‚¹
    - åˆ†é¡: DecisionTreeClassifierã‚¯ãƒ©ã‚¹

ä»¥ä¸‹ã§ã¯cancerãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦æ±ºå®šæœ¨ã‚’ä½œæˆã—ã€æåˆˆã‚Šã®åŠ¹æœã‚’ç¢ºèªã™ã‚‹ã€‚ã¾ãšã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®è¨­å®šã§è¨“ç·´ã‚»ãƒƒãƒˆã«å¯¾ã—ã¦æœ¨ã‚’æ§‹ç¯‰ã™ã‚‹ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã¯è‘‰ãŒç´”ç²‹ã«ãªã‚‹ã¾ã§åˆ†é¡ã™ã‚‹ã€‚


```python
from sklearn.tree import DecisionTreeClassifier
cancer = load_breast_cancer()
X_train, X_test, y_train, y_test = train_test_split(
  cancer.data, cancer.target, stratify=cancer.target, random_state = 42
)
tree = DecisionTreeClassifier(random_state = 0) # å†…éƒ¨ã§ã‚¿ã‚¤ãƒ–ãƒ¬ãƒ¼ã‚¯ã®åˆ¤å®šã«ä½¿ã†ä¹±æ•°ã‚’å›ºå®šã—ã¦ã„ã‚‹
tree.fit(X_train, y_train)
print("è¨“ç·´ã‚»ãƒƒãƒˆã«å¯¾ã™ã‚‹ç²¾åº¦:{:.3f}".format(tree.score(X_train, y_train)))
 ## è¨“ç·´ã‚»ãƒƒãƒˆã«å¯¾ã™ã‚‹ç²¾åº¦:1.000
print("ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã«å¯¾ã™ã‚‹ç²¾åº¦:{:.3f}".format(tree.score(X_test, y_test)))
 ## ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã«å¯¾ã™ã‚‹ç²¾åº¦:0.937
```

- è‘‰ãŒç´”ç²‹ã«ãªã‚‹ã¾ã§åˆ†å‰²ã—ã¦ã„ã‚‹ã®ã§ã€è¨“ç·´ã‚»ãƒƒãƒˆã«å¯¾ã™ã‚‹ç²¾åº¦ã¯å½“ç„¶1ã«ãªã‚‹ã€‚
- ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã«å¯¾ã™ã‚‹åˆ¶åº¦ã¯ç·šå½¢ãƒ¢ãƒ‡ãƒ«ã®ä¾‹ã§è¦‹ãŸæ™‚ã‚ˆã‚Šè‹¥å¹²ä½ã„ã€‚

æ¬¡ã«ã€æåˆˆã‚Šã®ä¾‹ã¨ã—ã¦æœ¨ã®æ·±ã•ã‚’4ã«å›ºå®šã—ã¦ã¿ã‚‹ã€‚


```python
tree = DecisionTreeClassifier(max_depth = 4, random_state = 0)
tree.fit(X_train, y_train)
print("è¨“ç·´ã‚»ãƒƒãƒˆã«å¯¾ã™ã‚‹ç²¾åº¦:{:.3f}".format(tree.score(X_train, y_train)))
 ## è¨“ç·´ã‚»ãƒƒãƒˆã«å¯¾ã™ã‚‹ç²¾åº¦:0.988
print("ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã«å¯¾ã™ã‚‹ç²¾åº¦:{:.3f}".format(tree.score(X_test, y_test)))
 ## ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã«å¯¾ã™ã‚‹ç²¾åº¦:0.951
```

è¨“ç·´ã‚»ãƒƒãƒˆã«å¯¾ã™ã‚‹ç²¾åº¦ã¨å¼•ãæ›ãˆã«ã€æ±åŒ–æ€§èƒ½ãŒå‘ä¸Šã—ã¦ã„ã‚‹ã“ã¨ãŒåˆ†ã‹ã‚‹ã€‚

### æ±ºå®šæœ¨ã®è§£æ

- æœ¨ã®å¯è¦–åŒ–ã®ãŸã‚ã«ã€ã¾ãšã¯`tree`ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®`export_graphviz`é–¢æ•°ã§ã‚°ãƒ©ãƒ•ã‚’æ›¸ãå‡ºã™ã€‚
- å‡ºåŠ›ã¯ã‚°ãƒ©ãƒ•ã«å¯¾å¿œã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã§ã‚ã‚‹.dotå½¢å¼ã®ãƒ•ã‚¡ã‚¤ãƒ«ã€‚


```python
from sklearn.tree import export_graphviz
export_graphviz(
  tree, out_file = "output/tree.dot", class_names = ["malignant", "benign"],
  feature_names = cancer.feature_names, impurity = False, filled = True
  )
```

- .dotãƒ•ã‚¡ã‚¤ãƒ«ã®å¯è¦–åŒ–ã¯graphvizãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã§è¡Œã†


```python
import graphviz
from PIL import Image
with open("output/tree.dot") as f:
  dot_graph = f.read()
g = graphviz.Source(dot_graph)
g.format = "png"
g.render("output/tree.gv")
img = np.array(Image.open("output/tree.gv.png"))
plt.imshow(img)
plt.axis('off')
```

![](02_supervised_learning_files/figure-html/unnamed-chunk-71-1.png)<!-- -->

å¯è¦–åŒ–ã—ãŸæœ¨ã¯å¤šãã®æƒ…å ±ã‚’å«ã‚€ãŒã€ç‰¹ã«**å¤§éƒ¨åˆ†ã®ãƒ‡ãƒ¼ã‚¿ãŒé€šã‚‹ãƒ‘ã‚¹ã¯ã©ã“ã‹ï¼Ÿ**ã«æ³¨ç›®ã™ã‚‹ã¨è‰¯ã„ã€‚

### æ±ºå®šæœ¨ã®ç‰¹å¾´é‡ã®é‡è¦æ€§

æ±ºå®šæœ¨å…¨ä½“ã‚’ç¢ºèªã—ã€æŠŠæ¡ã™ã‚‹ã®ã¯å¤§å¤‰ãªä½œæ¥­ãªã®ã§ã€ä»¥ä¸‹ã®ã‚ˆã†ãªæƒ…å ±ãŒä½¿ç”¨ã•ã‚Œã‚‹å ´åˆãŒã‚ã‚‹ã€‚

- **ç‰¹å¾´é‡ã®é‡è¦åº¦** (feature importance) å€‹ã€…ã®ç‰¹å¾´é‡ã¯ãã‚Œãã‚Œã®åˆ¤æ–­ã«å¯¾ã—ã¦ã©ã®ç¨‹åº¦é‡è¦ãªã®ã‹ï¼Ÿ
    - 1ã«è¿‘ã„ã»ã©é‡è¦ã€‚1ã§ã‚ã‚Œã°ãã®ç‰¹å¾´é‡ã ã‘ã§å®Œå…¨ã«åˆ¤åˆ¥ãŒã§ãã‚‹ã¨ã„ã†ã“ã¨ã€‚
    - 0ã«è¿‘ã„ã»ã©é‡è¦ã§ã¯ãªã„

ç‰¹å¾´é‡ã®é‡è¦åº¦ã¯ãƒ•ã‚£ãƒƒãƒˆæ¸ˆã¿ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®`.feature_importance_`ã«æ ¼ç´ã•ã‚Œã¦ã„ã‚‹ã€‚    
    

```python
print(tree.feature_importances_)
 ## [0.         0.         0.         0.         0.         0.
 ##  0.         0.         0.         0.         0.01019737 0.04839825
 ##  0.         0.         0.0024156  0.         0.         0.
 ##  0.         0.         0.72682851 0.0458159  0.         0.
 ##  0.0141577  0.         0.018188   0.1221132  0.01188548 0.        ]
```

ã“ã®ã¾ã¾ã§ã¯ã‚ã‹ã‚Šã«ãã„ã®ã§ãƒ—ãƒ­ãƒƒãƒˆã—ã¦ã¿ã‚‹ã€‚


```python
n_features = cancer.data.shape[1]
plt.barh(range(n_features), tree.feature_importances_, align = 'center')
plt.yticks(np.arange(n_features), cancer.feature_names)
plt.xlabel("ç‰¹å¾´é‡ã®é‡è¦åº¦")
plt.ylabel("ç‰¹å¾´é‡")
```

![](02_supervised_learning_files/figure-html/unnamed-chunk-74-1.png)<!-- -->

- **ç‰¹å¾´é‡ã®é‡è¦åº¦ãŒé«˜ã„ç‰¹å¾´é‡**ã¯é‡è¦ã ãŒã€é€†ã¯å¿…ãšã—ã‚‚æˆã‚Šç«‹ãŸãªã„ã¨ã„ã†ç‚¹ã«æ³¨æ„ãŒå¿…è¦ã§ã‚ã‚‹ã€‚
    - ç‰¹å¾´é‡é–“ã«å¼·ã„ç›¸é–¢ãŒã‚ã‚Šã€ã„ãšã‚Œã‹ã®ç‰¹å¾´é‡ã§ååˆ†èª¬æ˜å‡ºæ¥ã¦ã—ã¾ã†å ´åˆã¯ã€æ®‹ã‚Šã®ç‰¹å¾´é‡ãŒãŸã¾ãŸã¾æ¡ç”¨ã•ã‚Œãªã„ã¨ã„ã†ã“ã¨ãŒã‚ã‚Šã†ã‚‹ã€‚
- ç‰¹å¾´é‡ã®é‡è¦åº¦ã¯ä¿‚æ•°ã¨ç•°ãªã£ã¦å¸¸ã«æ­£ã§ã‚ã‚Šã€ãã®ç‰¹å¾´é‡ãŒå¤§ãã„ã¨ã‚¯ãƒ©ã‚¹ãŒã©ã‚Œã«ãªã‚‹ã®ã‹ã¯ç›´æ¥ã¯åˆ†ã‹ã‚‰ãªã„ã€‚
- ä¸Šè¨˜ã®ä¾‹ã§ã¯worst radiusã¯å°‘ãªãã¨ã‚‚é‡è¦ã ãŒã€ä»–ã«é‡è¦ãªç‰¹å¾´é‡ãŒã‚ã‚‹å¯èƒ½æ€§ã¯é™¤å¤–ã§ããªã„ã—ã€worst radiusã®å€¤ã¨è‰¯æ€§ãƒ»æ‚ªæ€§ã®é–¢ä¿‚ãŒã©ã®ã‚ˆã†ã«ãªã£ã¦ã„ã‚‹ã®ã‹ã‚‚è‡ªæ˜ã§ã¯ãªã„ã€‚

ãã‚‚ãã‚‚ã€ç‰¹å¾´é‡ã¨ã‚¯ãƒ©ã‚¹ã®é–¢ä¿‚ã¯å¿…ãšã—ã‚‚å˜ç´”ã¨ã¯é™ã‚‰ãªã„ã€‚ä¾‹ãˆã°æ¬¡ã®ã‚ˆã†ãª2ã¤ã®ç‰¹å¾´é‡ã‹ã‚‰ãªã‚‹2ã‚¯ãƒ©ã‚¹åˆ†é¡å•é¡Œã‚’è€ƒãˆã¦ã¿ã‚‹ã€‚ã“ã®ä¾‹ã¯ã€ã‚¯ãƒ©ã‚¹ã‚’åˆ†ã‘ã‚‹ãƒ«ãƒ¼ãƒ«ã¯å˜ç´”ã§æ˜ç¢ºã ãŒã€ã‚¯ãƒ©ã‚¹1ã¯ã‚¯ãƒ©ã‚¹0ã®ä¸­ã«åˆ†å¸ƒã—ã¦ã„ã‚‹ã®ã§ã€ä¸€å®šã®å¤§å°é–¢ä¿‚ã ã‘ã§ã¯åˆ†é¡ã§ããªã„ã€‚


```python
tree = mglearn.plots.plot_tree_not_monotone()
 ## Feature importances: [0. 1.]
```

![](02_supervised_learning_files/figure-html/unnamed-chunk-76-1.png)<!-- -->


```python
tree.format = "png"
tree.render("output/not_monotone.gv")
img = np.array(Image.open("output/not_monotone.gv.png"))
plt.imshow(img)
plt.axis('off')
```

![](02_supervised_learning_files/figure-html/unnamed-chunk-78-1.png)<!-- -->

- æ±ºå®šæœ¨ã«ã‚ˆã‚‹åˆ†é¡ã®è­°è«–ã¯æ±ºå®šæœ¨ã«ã‚ˆã‚‹å›å¸°ã«ã‚‚å½“ã¦ã¯ã¾ã‚‹ã€‚
- æ±ºå®šæœ¨ã«ã‚ˆã‚‹å›å¸°ã§ã¯ã€**å¤–æŒ¿** (extrapolate)ãŒã§ããªã„ç‚¹ã«æ³¨æ„ã™ã‚‹ã€‚

æ±ºå®šæœ¨ã¯å¤–æŒ¿ãŒã§ããªã„ã¨ã„ã†ç‚¹ã«ã¤ã„ã¦ã€RAMä¾¡æ ¼ã®æ¨ç§»ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ã£ã¦ä¾‹ã‚’ç¤ºãã†ã€‚


```python
import os
ram_prices = pd.read_csv(os.path.join(mglearn.datasets.DATA_PATH, "ram_price.csv"))
plt.semilogy(ram_prices.date, ram_prices.price)
plt.xlabel("å¹´")
plt.ylabel("1Mãƒã‚¤ãƒˆã‚ãŸã‚Šã®ä¾¡æ ¼($)")
```

![](02_supervised_learning_files/figure-html/unnamed-chunk-80-1.png)<!-- -->

é–¢ä¿‚ã‚’ç›´ç·šçš„ã«ã™ã‚‹ãŸã‚ã«ã€ä¾¡æ ¼ã‚’å¯¾æ•°å¤‰æ›ã—ã¦ã„ã‚‹ã¨ã„ã†ç‚¹ã«æ³¨æ„ã—ã¦ã‚‚ã‚‰ã„ãŸã„ã€‚ã“ã®ç¨®ã®å¤‰æ›ã¯ç·šå½¢å›å¸°ã‚’è¡Œã†éš›ã«é‡è¦ã¨ãªã‚‹ã€‚

ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«å¯¾ã—ã€ç·šå½¢å›å¸°ã¨å›å¸°æœ¨ã‚’é©ç”¨ã™ã‚‹ã€‚ã“ã“ã§ã¯ã€2000å¹´ã‚ˆã‚Šå‰ã®ãƒ‡ãƒ¼ã‚¿ã‚’è¨“ç·´ã‚»ãƒƒãƒˆã¨ã—ã€2000å¹´ä»¥é™ã®ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã¨ã™ã‚‹ã€‚ã¤ã¾ã‚Šã€éå»ã®ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å°†æ¥ã‚’äºˆæ¸¬ã™ã‚‹ã€‚


```python
from sklearn.tree import DecisionTreeRegressor
data_train = ram_prices[ram_prices.date < 2000]
data_test = ram_prices[ram_prices.date >= 2000]
X_train = data_train.date[:, np.newaxis]
y_train = np.log(data_train.price) #å¯¾æ•°å¤‰æ›
# ãƒ¢ãƒ‡ãƒ«ã«è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚£ãƒƒãƒˆã•ã›ã‚‹
tree = DecisionTreeRegressor().fit(X_train, y_train)
linear_reg = LinearRegression().fit(X_train, y_train)
# 2000å¹´ä»¥é™ã‚‚å«ã‚ãŸå…¨ã¦ã®ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆã«å¯¾ã—ã¦äºˆæ¸¬ã‚’è¡Œã†
X_all = ram_prices.date[:, np.newaxis]
pred_tree = tree.predict(X_all)
pred_lr = linear_reg.predict(X_all)
price_tree = np.exp(pred_tree) #å¯¾æ•°å¤‰æ›ã‚’è§£é™¤
price_lr = np.exp(pred_lr)
## ãƒ—ãƒ­ãƒƒãƒˆ
plt.semilogy(data_train.date, data_train.price, label = "è¨“ç·´ãƒ‡ãƒ¼ã‚¿")
plt.semilogy(data_test.date, data_test.price, label = "ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿")
plt.semilogy(ram_prices.date, price_tree, label = "å›å¸°æœ¨")
plt.semilogy(ram_prices.date, price_lr, label = "ç·šå½¢å›å¸°")
plt.legend()
```


```python
plt.tight_layout()
plt.show()
```

![](02_supervised_learning_files/figure-html/unnamed-chunk-82-1.png)<!-- -->

```python
plt.close()
```

ç·šå½¢å›å¸°ã¯2000å¹´ä»¥é™ã®å€¤ã‚‚äºˆæ¸¬å‡ºæ¥ã¦ã„ã‚‹ã®ã«å¯¾ã—ã¦ã€å›å¸°æœ¨ã¯å˜ã«2000å¹´ã®å€¤ã‚’è¿”ã™ã ã‘ã«ãªã£ã¦ã„ã‚‹ã€‚

### é•·æ‰€ã€çŸ­æ‰€ã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿

- æ±ºå®šæœ¨ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯äº‹å‰æåˆˆã‚Šã«é–¢ã™ã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ã‚ã‚‹ã€‚
- å¤§æŠµã®å ´åˆã¯max_depthã€max_leaf_nodesã€min_samples_leafã®ã„ãšã‚Œã‹1ã¤ã®æŒ‡å®šã§ååˆ†ã§ã‚ã‚‹ã€‚
- æ±ºå®šæœ¨ã¯å®¹æ˜“ã«å¯è¦–åŒ–å¯èƒ½ã§ã‚ã‚Šã€ç†è§£ã—ã‚„ã™ã„ã€‚
- æ±ºå®šæœ¨ã®åˆ†å‰²ã¯ç‰¹å¾´é‡æ¯ã«è¡Œã‚ã‚Œã‚‹ãŸã‚ã€ç‰¹å¾´é‡ã‚’æ­£è¦åŒ–ã—ãŸã‚Šæ¨™æº–åŒ–ã—ãŸã‚Šã™ã‚‹å¿…è¦ã¯ãªã„ã€‚
- ç‰¹å¾´é‡ã®æœ€å¤§ã®æ¬ ç‚¹ã¯äº‹å‰æåˆˆã‚Šã‚’è¡Œã£ãŸã¨ã—ã¦ã‚‚éå‰°é©åˆã—ã‚„ã™ãã€æ±åŒ–æ€§èƒ½ãŒä½ããªã‚Šã‚„ã™ã„ã¨ã„ã†ç‚¹ã§ã‚ã‚‹ã€‚
