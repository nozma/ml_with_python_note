[
["index.html", "Pythonã§å§‹ã‚ã‚‹æ©Ÿæ¢°å­¦ç¿’ã®å­¦ç¿’ ã¾ãˆãŠã", " Pythonã§å§‹ã‚ã‚‹æ©Ÿæ¢°å­¦ç¿’ã®å­¦ç¿’ R. Ito 2018-03-08 ã¾ãˆãŠã ã‚„ã‚‹ãã„(à¹‘â€¢Ì€ã…‚â€¢Ì)Ùˆâœ§ "],
["e696b9e9879d.html", "æ–¹é‡", " æ–¹é‡ ãƒ†ã‚­ã‚¹ãƒˆã®ã‚³ãƒ¼ãƒ‰ã¯è¦‹ãŸç›®é‡è¦–ã§å†—é•·ãªã®ã§ã€ã©ã‚“ã©ã‚“çœç•¥ã—ã¦ã„ãã¾ã™ã€‚ ãŒã‚“ã°ã‚Šã™ããªã„ã€‚ "],
["e59fb7e7ad86e792b0e5a283e381a8e3818b.html", "åŸ·ç­†ç’°å¢ƒã¨ã‹", " åŸ·ç­†ç’°å¢ƒã¨ã‹ ãã®ã†ã¡æ›¸ãã€‚ "],
["section-1.html", "1 ã¯ã˜ã‚ã«", " 1 ã¯ã˜ã‚ã« çœŸã®å‰ç½®ãçš„ãªã‚„ã¤ã€‚ "],
["section-1-1.html", "1.1 ãªãœæ©Ÿæ¢°å­¦ç¿’ãªã®ã‹", " 1.1 ãªãœæ©Ÿæ¢°å­¦ç¿’ãªã®ã‹ ifã€œthenã€œã®ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã‚·ã‚¹ãƒ†ãƒ ã«ã¯é™ç•ŒãŒã‚ã‚‹ã€‚ ãƒ­ã‚¸ãƒƒã‚¯ãŒãƒ‰ãƒ¡ã‚¤ãƒ³å›ºæœ‰ã®ã‚‚ã®ã«ãªã‚Šã€ã‚¿ã‚¹ã‚¯ãŒå¤‰åŒ–ã—ãŸã‚‰ä½œã‚Šç›´ã•ãªã„ã¨ã„ã‘ãªã„ã€‚ äººé–“ã®ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã®æ€è€ƒã«å¯¾ã™ã‚‹æ·±ã„ç†è§£ãŒå¿…è¦ã€‚ é¡”èªè­˜ã¨ã‹ã¯ã¡ã‚‡ã£ã¨ç„¡ç†ã€‚ 1.1.1 æ©Ÿæ¢°å­¦ç¿’ã§è§£æ±ºå¯èƒ½ãªå•é¡Œ ä¸–ã®ä¸­ã«ã¯æ•™å¸«ã®ã‚ã‚‹å­¦ç¿’ã¨æ•™å¸«ã®ãªã„å­¦ç¿’ãŒã‚ã‚‹ã€‚ æ•™å¸«ã‚ã‚Šå­¦ç¿’ å…¥åŠ›ã¨å‡ºåŠ›ã®ãƒšã‚¢ã‚’ä¸ãˆã¦ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’å­¦ç¿’ã•ã›ã‚‹ã€‚ æœªçŸ¥ã®å…¥åŠ›ã«å¯¾ã™ã‚‹å‡ºåŠ›ã‚’äºˆæ¸¬ã™ã‚‹ã€‚ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’é›†ã‚ã‚‹ã“ã¨ãŒå¤§å¤‰ãªå ´åˆã‚‚ã‚ã‚‹ã€‚ æ•™å¸«ãªã—å­¦ç¿’ å‡ºåŠ›ã®ãªã„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’å­¦ç¿’ã•ã›ã‚‹ã€‚ ãƒˆãƒ”ãƒƒã‚¯è§£æã‚„ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã€ç•°å¸¸æ¤œçŸ¥ãªã©ã€‚ ã‚µãƒ³ãƒ—ãƒ«ã¨ç‰¹å¾´é‡ã€‚ ã‚µãƒ³ãƒ—ãƒ« å€‹ã€…ã®ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã¾ãŸã¯é‡ã€‚ ç‰¹å¾´é‡ ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã®æŒã¤ç‰¹æ€§ã‚’è¡¨ç¾ã™ã‚‹åˆ—ã€‚ æƒ…å ±é‡ã®ãªã„ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã¯å­¦ç¿’ã§ããªã„ã“ã¨ã‚’è¦šãˆã¦ãŠãã“ã¨ã€‚ 1.1.2 ã‚¿ã‚¹ã‚¯ã‚’çŸ¥ã‚Šã€ãƒ‡ãƒ¼ã‚¿ã‚’çŸ¥ã‚‹ ã‚ˆããƒ‡ãƒ¼ã‚¿ã‚’ç†è§£ã™ã‚‹ã“ã¨ ãã®ãƒ‡ãƒ¼ã‚¿ã§ãã‚‚ãã‚‚å•é¡Œã‚’è§£æ±ºã§ãã‚‹ã®ã‹ï¼Ÿ ã©ã‚“ãªæ©Ÿæ¢°å­¦ç¿’ã®å•é¡Œã«ç½®ãæ›ãˆã‚‹ã¹ãã‹ï¼Ÿ ãƒ‡ãƒ¼ã‚¿ã®æ•°ã¯ååˆ†ã‹ï¼Ÿ ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¯å•é¡Œã®ä¸€éƒ¨ã«ã™ããªã„ã€‚å…¨ä½“ã‚’å¿ƒã«ç•™ã‚ã¦ãŠãã“ã¨ã€‚ "],
["python.html", "1.2 ãªãœPythonãªã®ã‹ï¼Ÿ", " 1.2 ãªãœPythonãªã®ã‹ï¼Ÿ ã¤ã‚ˆã„ æ±ç”¨è¨€èªã®å¼·ã•ã¨ãƒ‰ãƒ¡ã‚¤ãƒ³ç‰¹ä¾¡ã‚¹ã‚¯ãƒªãƒ—ãƒˆè¨€èªã®å¼·ã•ãŒã‚ã‚‹ã€‚ Jupyter NotebookãŒä½¿ãˆã‚‹ ãƒ‡ãƒ¼ã‚¿è§£æã¯ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªéç¨‹ã€‚ "],
["scikit-learn.html", "1.3 scikit-learn", " 1.3 scikit-learn Pythonã§æ©Ÿæ¢°å­¦ç¿’ã¨ã„ã£ãŸã‚‰ã“ã‚Œ ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¬ã‚¤ãƒ‰ã‚‚èª­ã‚“ã§ãŠã“ã†ãª http://scikit-learn.org/stable/user_guide.html 1.3.1 ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ« $ pip install numpy scipy matplotlib ipython scikit-learn pandas pillow æœ€è¿‘ã¯anacondaä½¿ã‚ãšã«venvã‚„Dockerä½¿ã†ã®ãŒæµã‚Œã£ã½ã„æ°—ãŒã—ã¾ã™ãŒPythonç•Œéšˆã®ç’°å¢ƒæ§‹ç¯‰ã¯ã™ãã«ä¸»æµãŒå¤‰ã‚ã‚‹ã®ã§æ­£ç›´ã‚ˆãåˆ†ã‹ã‚Šã¾ã›ã‚“ã€‚ "],
["section-1-4.html", "1.4 å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¨ãƒ„ãƒ¼ãƒ«", " 1.4 å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¨ãƒ„ãƒ¼ãƒ« Jupyter Notebook ãƒ–ãƒ©ã‚¦ã‚¶ä¸Šã§Markdownã¨ã‚³ãƒ¼ãƒ‰æ··ãœã¦æ›¸ã‘ã‚‹ã‚„ã¤ã€‚ NumPy é…åˆ—è¨ˆç®—ï¾’ï½¯ï¾ï½¬ï¾Šï¾”ï½²ã‚„ã¤ SciPy ç§‘å­¦æŠ€è¡“è¨ˆç®—ã§ãã‚‹ã‚„ã¤ matplotlib ãƒ—ãƒ­ãƒƒãƒˆã™ã‚‹ã‚„ã¤ pandas Rã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ çš„ãªæ„Ÿã˜ã§ãƒ‡ãƒ¼ã‚¿æ‰±ãˆã‚‹ã‚„ã¤ mglearn ã€Œã“ã¡ã‚‰ã«äºˆã‚èª¿ç†ã—ãŸã‚‚ã®ãŒã‚ã‚Šã¾ã™ã€çš„ã«æ•™ç§‘æ›¸ã®ä¾‹è©¦ã›ã‚‹ã‚„ã¤ "],
["python-2-vs-python-3.html", "1.5 Python 2 vs. Python 3", " 1.5 Python 2 vs. Python 3 3ã§ã‚„ã‚Œã€‚ "],
["-.html", "1.6 æœ€åˆã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³: ã‚¢ã‚¤ãƒªã‚¹ã®ã‚¯ãƒ©ã‚¹åˆ†é¡", " 1.6 æœ€åˆã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³: ã‚¢ã‚¤ãƒªã‚¹ã®ã‚¯ãƒ©ã‚¹åˆ†é¡ ã¿ã‚“ãªå¤§å¥½ãirisã€‚ ä»¥ä¸‹ã®è¨˜äº‹ãŒè©³ã—ã„ã€‚ irisã®æ­£ä½“ (R Advent Calendar 2012 6æ—¥ç›®) - ã©ã‚“ãªé³¥ã‚‚ 1.6.1 ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã‚€ scikit-learnã®datasetsãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ« ã„ã‚ã‚“ãªã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒå…¥ã£ã¦ã‚‹ã€‚ sklearn.datasets.load_iris()ã§irisãŒè¿”ã£ã¦ãã‚‹ã®ã§é©å½“ã«å—ã‘ã‚ˆã†ã€‚ from sklearn.datasets import load_iris iris_dataset = load_iris() load_iris()ã¯Bunchã‚¯ãƒ©ã‚¹ã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’è¿”ã™ã€‚ã“ã‚Œã¯ãƒ‡ã‚£ã‚¯ã‚·ãƒ§ãƒŠãƒªã¿ãŸã„ã«æ‰±ãˆã‚‹ã€‚å€¤ã«ã¯iris_dataset['data']ä»¥å¤–ã«iris_dataset.dataã¿ãŸã„ã«ã‚¢ã‚¯ã‚»ã‚¹ã—ã¦ã‚‚ã„ã„ã€‚ print(iris_dataset.keys()) ## dict_keys([&#39;data&#39;, &#39;target&#39;, &#39;target_names&#39;, &#39;DESCR&#39;, &#39;feature_names&#39;]) ã‚­ãƒ¼DESCRã®ä¸­ã«ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®èª¬æ˜ãŒå…¥ã£ã¦ã„ã‚‹ã€‚ print(iris_dataset.DESCR) ## Iris Plants Database ## ==================== ## ## Notes ## ----- ## Data Set Characteristics: ## :Number of Instances: 150 (50 in each of three classes) ## :Number of Attributes: 4 numeric, predictive attributes and the class ## :Attribute Information: ## - sepal length in cm ## - sepal width in cm ## - petal length in cm ## - petal width in cm ## - class: ## - Iris-Setosa ## - Iris-Versicolour ## - Iris-Virginica ## :Summary Statistics: ## ## ============== ==== ==== ======= ===== ==================== ## Min Max Mean SD Class Correlation ## ============== ==== ==== ======= ===== ==================== ## sepal length: 4.3 7.9 5.84 0.83 0.7826 ## sepal width: 2.0 4.4 3.05 0.43 -0.4194 ## petal length: 1.0 6.9 3.76 1.76 0.9490 (high!) ## petal width: 0.1 2.5 1.20 0.76 0.9565 (high!) ## ============== ==== ==== ======= ===== ==================== ## ## :Missing Attribute Values: None ## :Class Distribution: 33.3% for each of 3 classes. ## :Creator: R.A. Fisher ## :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov) ## :Date: July, 1988 ## ## This is a copy of UCI ML iris datasets. ## http://archive.ics.uci.edu/ml/datasets/Iris ## ## The famous Iris database, first used by Sir R.A Fisher ## ## This is perhaps the best known database to be found in the ## pattern recognition literature. Fisher&#39;s paper is a classic in the field and ## is referenced frequently to this day. (See Duda &amp; Hart, for example.) The ## data set contains 3 classes of 50 instances each, where each class refers to a ## type of iris plant. One class is linearly separable from the other 2; the ## latter are NOT linearly separable from each other. ## ## References ## ---------- ## - Fisher,R.A. &quot;The use of multiple measurements in taxonomic problems&quot; ## Annual Eugenics, 7, Part II, 179-188 (1936); also in &quot;Contributions to ## Mathematical Statistics&quot; (John Wiley, NY, 1950). ## - Duda,R.O., &amp; Hart,P.E. (1973) Pattern Classification and Scene Analysis. ## (Q327.D83) John Wiley &amp; Sons. ISBN 0-471-22361-1. See page 218. ## - Dasarathy, B.V. (1980) &quot;Nosing Around the Neighborhood: A New System ## Structure and Classification Rule for Recognition in Partially Exposed ## Environments&quot;. IEEE Transactions on Pattern Analysis and Machine ## Intelligence, Vol. PAMI-2, No. 1, 67-71. ## - Gates, G.W. (1972) &quot;The Reduced Nearest Neighbor Rule&quot;. IEEE Transactions ## on Information Theory, May 1972, 431-433. ## - See also: 1988 MLC Proceedings, 54-64. Cheeseman et al&quot;s AUTOCLASS II ## conceptual clustering system finds 3 classes in the data. ## - Many, many more ... targetã¯ç¬¦å·åŒ–ã•ã‚Œã¦ã„ã¦ã€å¯¾å¿œã™ã‚‹åå‰ã¯target_namesã«å…¥ã£ã¦ã„ã‚‹ã€‚ print(iris_dataset.target) ## [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ## 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 ## 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 ## 2 2] print(iris_dataset.target_names) ## [&#39;setosa&#39; &#39;versicolor&#39; &#39;virginica&#39;] è¦ã™ã‚‹ã«targetã§target_namesã‚’å‚ç…§ã™ã‚‹ã¨å®Ÿéš›ã®ç›®çš„å¤‰æ•°ã®æ§‹é€ ãŒè¦‹ãˆã‚‹ã€‚ print(iris_dataset.target_names[iris_dataset.target]) ## [&#39;setosa&#39; &#39;setosa&#39; &#39;setosa&#39; &#39;setosa&#39; &#39;setosa&#39; &#39;setosa&#39; &#39;setosa&#39; &#39;setosa&#39; ## &#39;setosa&#39; &#39;setosa&#39; &#39;setosa&#39; &#39;setosa&#39; &#39;setosa&#39; &#39;setosa&#39; &#39;setosa&#39; &#39;setosa&#39; ## &#39;setosa&#39; &#39;setosa&#39; &#39;setosa&#39; &#39;setosa&#39; &#39;setosa&#39; &#39;setosa&#39; &#39;setosa&#39; &#39;setosa&#39; ## &#39;setosa&#39; &#39;setosa&#39; &#39;setosa&#39; &#39;setosa&#39; &#39;setosa&#39; &#39;setosa&#39; &#39;setosa&#39; &#39;setosa&#39; ## &#39;setosa&#39; &#39;setosa&#39; &#39;setosa&#39; &#39;setosa&#39; &#39;setosa&#39; &#39;setosa&#39; &#39;setosa&#39; &#39;setosa&#39; ## &#39;setosa&#39; &#39;setosa&#39; &#39;setosa&#39; &#39;setosa&#39; &#39;setosa&#39; &#39;setosa&#39; &#39;setosa&#39; &#39;setosa&#39; ## &#39;setosa&#39; &#39;setosa&#39; &#39;versicolor&#39; &#39;versicolor&#39; &#39;versicolor&#39; &#39;versicolor&#39; ## &#39;versicolor&#39; &#39;versicolor&#39; &#39;versicolor&#39; &#39;versicolor&#39; &#39;versicolor&#39; ## &#39;versicolor&#39; &#39;versicolor&#39; &#39;versicolor&#39; &#39;versicolor&#39; &#39;versicolor&#39; ## &#39;versicolor&#39; &#39;versicolor&#39; &#39;versicolor&#39; &#39;versicolor&#39; &#39;versicolor&#39; ## &#39;versicolor&#39; &#39;versicolor&#39; &#39;versicolor&#39; &#39;versicolor&#39; &#39;versicolor&#39; ## &#39;versicolor&#39; &#39;versicolor&#39; &#39;versicolor&#39; &#39;versicolor&#39; &#39;versicolor&#39; ## &#39;versicolor&#39; &#39;versicolor&#39; &#39;versicolor&#39; &#39;versicolor&#39; &#39;versicolor&#39; ## &#39;versicolor&#39; &#39;versicolor&#39; &#39;versicolor&#39; &#39;versicolor&#39; &#39;versicolor&#39; ## &#39;versicolor&#39; &#39;versicolor&#39; &#39;versicolor&#39; &#39;versicolor&#39; &#39;versicolor&#39; ## &#39;versicolor&#39; &#39;versicolor&#39; &#39;versicolor&#39; &#39;versicolor&#39; &#39;versicolor&#39; ## &#39;versicolor&#39; &#39;virginica&#39; &#39;virginica&#39; &#39;virginica&#39; &#39;virginica&#39; &#39;virginica&#39; ## &#39;virginica&#39; &#39;virginica&#39; &#39;virginica&#39; &#39;virginica&#39; &#39;virginica&#39; &#39;virginica&#39; ## &#39;virginica&#39; &#39;virginica&#39; &#39;virginica&#39; &#39;virginica&#39; &#39;virginica&#39; &#39;virginica&#39; ## &#39;virginica&#39; &#39;virginica&#39; &#39;virginica&#39; &#39;virginica&#39; &#39;virginica&#39; &#39;virginica&#39; ## &#39;virginica&#39; &#39;virginica&#39; &#39;virginica&#39; &#39;virginica&#39; &#39;virginica&#39; &#39;virginica&#39; ## &#39;virginica&#39; &#39;virginica&#39; &#39;virginica&#39; &#39;virginica&#39; &#39;virginica&#39; &#39;virginica&#39; ## &#39;virginica&#39; &#39;virginica&#39; &#39;virginica&#39; &#39;virginica&#39; &#39;virginica&#39; &#39;virginica&#39; ## &#39;virginica&#39; &#39;virginica&#39; &#39;virginica&#39; &#39;virginica&#39; &#39;virginica&#39; &#39;virginica&#39; ## &#39;virginica&#39; &#39;virginica&#39; &#39;virginica&#39;] ç‰¹å¾´é‡ã¯ãƒ‡ãƒ¼ã‚¿ä»¶æ•°Ã—ç‰¹å¾´é‡æ•°ã®NumPyé…åˆ—ã¨ã—ã¦dataã«å…¥ã£ã¦ã„ã‚‹ã€‚ print(iris_dataset.data) ## [[5.1 3.5 1.4 0.2] ## [4.9 3. 1.4 0.2] ## [4.7 3.2 1.3 0.2] ## [4.6 3.1 1.5 0.2] ## [5. 3.6 1.4 0.2] ## [5.4 3.9 1.7 0.4] ## [4.6 3.4 1.4 0.3] ## [5. 3.4 1.5 0.2] ## [4.4 2.9 1.4 0.2] ## [4.9 3.1 1.5 0.1] ## [5.4 3.7 1.5 0.2] ## [4.8 3.4 1.6 0.2] ## [4.8 3. 1.4 0.1] ## [4.3 3. 1.1 0.1] ## [5.8 4. 1.2 0.2] ## [5.7 4.4 1.5 0.4] ## [5.4 3.9 1.3 0.4] ## [5.1 3.5 1.4 0.3] ## [5.7 3.8 1.7 0.3] ## [5.1 3.8 1.5 0.3] ## [5.4 3.4 1.7 0.2] ## [5.1 3.7 1.5 0.4] ## [4.6 3.6 1. 0.2] ## [5.1 3.3 1.7 0.5] ## [4.8 3.4 1.9 0.2] ## [5. 3. 1.6 0.2] ## [5. 3.4 1.6 0.4] ## [5.2 3.5 1.5 0.2] ## [5.2 3.4 1.4 0.2] ## [4.7 3.2 1.6 0.2] ## [4.8 3.1 1.6 0.2] ## [5.4 3.4 1.5 0.4] ## [5.2 4.1 1.5 0.1] ## [5.5 4.2 1.4 0.2] ## [4.9 3.1 1.5 0.1] ## [5. 3.2 1.2 0.2] ## [5.5 3.5 1.3 0.2] ## [4.9 3.1 1.5 0.1] ## [4.4 3. 1.3 0.2] ## [5.1 3.4 1.5 0.2] ## [5. 3.5 1.3 0.3] ## [4.5 2.3 1.3 0.3] ## [4.4 3.2 1.3 0.2] ## [5. 3.5 1.6 0.6] ## [5.1 3.8 1.9 0.4] ## [4.8 3. 1.4 0.3] ## [5.1 3.8 1.6 0.2] ## [4.6 3.2 1.4 0.2] ## [5.3 3.7 1.5 0.2] ## [5. 3.3 1.4 0.2] ## [7. 3.2 4.7 1.4] ## [6.4 3.2 4.5 1.5] ## [6.9 3.1 4.9 1.5] ## [5.5 2.3 4. 1.3] ## [6.5 2.8 4.6 1.5] ## [5.7 2.8 4.5 1.3] ## [6.3 3.3 4.7 1.6] ## [4.9 2.4 3.3 1. ] ## [6.6 2.9 4.6 1.3] ## [5.2 2.7 3.9 1.4] ## [5. 2. 3.5 1. ] ## [5.9 3. 4.2 1.5] ## [6. 2.2 4. 1. ] ## [6.1 2.9 4.7 1.4] ## [5.6 2.9 3.6 1.3] ## [6.7 3.1 4.4 1.4] ## [5.6 3. 4.5 1.5] ## [5.8 2.7 4.1 1. ] ## [6.2 2.2 4.5 1.5] ## [5.6 2.5 3.9 1.1] ## [5.9 3.2 4.8 1.8] ## [6.1 2.8 4. 1.3] ## [6.3 2.5 4.9 1.5] ## [6.1 2.8 4.7 1.2] ## [6.4 2.9 4.3 1.3] ## [6.6 3. 4.4 1.4] ## [6.8 2.8 4.8 1.4] ## [6.7 3. 5. 1.7] ## [6. 2.9 4.5 1.5] ## [5.7 2.6 3.5 1. ] ## [5.5 2.4 3.8 1.1] ## [5.5 2.4 3.7 1. ] ## [5.8 2.7 3.9 1.2] ## [6. 2.7 5.1 1.6] ## [5.4 3. 4.5 1.5] ## [6. 3.4 4.5 1.6] ## [6.7 3.1 4.7 1.5] ## [6.3 2.3 4.4 1.3] ## [5.6 3. 4.1 1.3] ## [5.5 2.5 4. 1.3] ## [5.5 2.6 4.4 1.2] ## [6.1 3. 4.6 1.4] ## [5.8 2.6 4. 1.2] ## [5. 2.3 3.3 1. ] ## [5.6 2.7 4.2 1.3] ## [5.7 3. 4.2 1.2] ## [5.7 2.9 4.2 1.3] ## [6.2 2.9 4.3 1.3] ## [5.1 2.5 3. 1.1] ## [5.7 2.8 4.1 1.3] ## [6.3 3.3 6. 2.5] ## [5.8 2.7 5.1 1.9] ## [7.1 3. 5.9 2.1] ## [6.3 2.9 5.6 1.8] ## [6.5 3. 5.8 2.2] ## [7.6 3. 6.6 2.1] ## [4.9 2.5 4.5 1.7] ## [7.3 2.9 6.3 1.8] ## [6.7 2.5 5.8 1.8] ## [7.2 3.6 6.1 2.5] ## [6.5 3.2 5.1 2. ] ## [6.4 2.7 5.3 1.9] ## [6.8 3. 5.5 2.1] ## [5.7 2.5 5. 2. ] ## [5.8 2.8 5.1 2.4] ## [6.4 3.2 5.3 2.3] ## [6.5 3. 5.5 1.8] ## [7.7 3.8 6.7 2.2] ## [7.7 2.6 6.9 2.3] ## [6. 2.2 5. 1.5] ## [6.9 3.2 5.7 2.3] ## [5.6 2.8 4.9 2. ] ## [7.7 2.8 6.7 2. ] ## [6.3 2.7 4.9 1.8] ## [6.7 3.3 5.7 2.1] ## [7.2 3.2 6. 1.8] ## [6.2 2.8 4.8 1.8] ## [6.1 3. 4.9 1.8] ## [6.4 2.8 5.6 2.1] ## [7.2 3. 5.8 1.6] ## [7.4 2.8 6.1 1.9] ## [7.9 3.8 6.4 2. ] ## [6.4 2.8 5.6 2.2] ## [6.3 2.8 5.1 1.5] ## [6.1 2.6 5.6 1.4] ## [7.7 3. 6.1 2.3] ## [6.3 3.4 5.6 2.4] ## [6.4 3.1 5.5 1.8] ## [6. 3. 4.8 1.8] ## [6.9 3.1 5.4 2.1] ## [6.7 3.1 5.6 2.4] ## [6.9 3.1 5.1 2.3] ## [5.8 2.7 5.1 1.9] ## [6.8 3.2 5.9 2.3] ## [6.7 3.3 5.7 2.5] ## [6.7 3. 5.2 2.3] ## [6.3 2.5 5. 1.9] ## [6.5 3. 5.2 2. ] ## [6.2 3.4 5.4 2.3] ## [5.9 3. 5.1 1.8]] dataã®å„åˆ—ã¯1ç¨®é¡ã®ç‰¹å¾´é‡ã«å¯¾å¿œã™ã‚‹ãŒã€å…·ä½“çš„ã«ãªã‚“ã¨ã„ã†ç‰¹å¾´é‡ãªã®ã‹ã¯feature_namesã«å…¥ã£ã¦ã„ã‚‹ã€‚ print(iris_dataset.feature_names) ## [&#39;sepal length (cm)&#39;, &#39;sepal width (cm)&#39;, &#39;petal length (cm)&#39;, &#39;petal width (cm)&#39;] NumPyé…åˆ—ã®æ‰±ã„æ–¹ã‚’ç°¡å˜ã«ã€‚é…åˆ—ã®å½¢çŠ¶(æ¬¡å…ƒ)ã¯shapeã§å–å¾—ã§ãã‚‹ã€‚ print(iris_dataset.data.shape) ## (150, 4) æ™®é€šã®é…åˆ—ã¿ãŸã„ã«ã‚¹ãƒ©ã‚¤ã‚¹ã§ãã‚‹ã€‚ print(iris_dataset.data[:5]) ## [[5.1 3.5 1.4 0.2] ## [4.9 3. 1.4 0.2] ## [4.7 3.2 1.3 0.2] ## [4.6 3.1 1.5 0.2] ## [5. 3.6 1.4 0.2]] 1.6.2 æˆåŠŸåº¦åˆã„ã®æ¸¬å®š: è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ æœªçŸ¥ã®æ¸¬å®šå€¤ã‹ã‚‰ã‚¢ãƒ¤ãƒ¡ã®å“ç¨®ã‚’äºˆæ¸¬ã™ã‚‹ã¿ãŸã„ãªã“ã¨ã‚„ã‚ŠãŸã„ã€‚ æœªçŸ¥ã®å…¥åŠ›ã«å¯¾ã™ã‚‹äºˆæ¸¬èƒ½åŠ› is æ±åŒ–èƒ½åŠ›ã€‚ ã“ã„ã¤ã‚’æœ€å¤§åŒ–ã™ã‚‹ã®ãŒç›®çš„ã€‚ è¨“ç·´ã«ä½¿ã£ãŸãƒ‡ãƒ¼ã‚¿ã¯ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡ã«ä½¿ãˆãªã„ã€‚ ãã®ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’æœ€é©åŒ–ã—ã¦ã„ã‚‹ã®ã§ã€è‰¯ã„æ€§èƒ½ãŒå‡ºã‚‹ã®ã¯å½“ç„¶ã€‚ ä¸€éƒ¨ã ã‘è¨“ç·´ã«ä½¿ã£ã¦æ®‹ã‚Šã‚’ãƒ†ã‚¹ãƒˆç”¨ã«å–ã£ã¦ãŠã‘ã°ã‚ˆã„ã®ã§ã¯ï¼Ÿ â†’ ãƒ›ãƒ¼ãƒ«ãƒ‰ã‚¢ã‚¦ãƒˆæ³• è¨“ç·´ã«ä½¿ã†ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ: è¨“ç·´ãƒ‡ãƒ¼ã‚¿ or è¨“ç·´ã‚»ãƒƒãƒˆã€‚ ãƒ†ã‚¹ãƒˆã«ä½¿ã†ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ: ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ or ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã€‚ scikit-learnã§ãƒ›ãƒ¼ãƒ«ãƒ‰ã‚¢ã‚¦ãƒˆæ³•ã‚’ã‚„ã‚‹ãªã‚‰model_selection.train_test_splitã€‚ scikit-learnçš„ãªæ…£ç¿’ (å…¥åŠ›)ãƒ‡ãƒ¼ã‚¿ã¯Xã§è¡¨ã™ ãƒ‡ãƒ¼ã‚¿ãƒ©ãƒ™ãƒ«(=å…¥åŠ›ã«å¯¾å¿œã™ã‚‹å‡ºåŠ›)ã¯yã§è¡¨ã™ å…¥åŠ›ã¯è¡Œåˆ—ã§å‡ºåŠ›ã¯ãƒ™ã‚¯ãƒˆãƒ«ãªã®ã§ã€\\(f(\\textbf{X}) = \\textbf{y}\\)ã¨ã„ã†ã“ã¨ã‚‰ã—ã„ã€‚ from sklearn.model_selection import train_test_split X_train, X_test, y_train, y_test = train_test_split( iris_dataset.data, iris_dataset.target, random_state = 0 ) å¼•æ•°random_stateã¯ä¹±æ•°ç¨®ã‚’å›ºå®šã™ã‚‹ã€‚å†ç¾æ€§ç¢ºä¿ã®ãŸã‚ã€‚ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§è¨“ç·´:ãƒ†ã‚¹ãƒˆ=3:1ã«åˆ†è§£ã™ã‚‹ã€‚ print(X_train.shape) ## (112, 4) print(y_train.shape) ## (112,) print(X_test.shape) ## (38, 4) print(y_test.shape) ## (38,) 1.6.3 æœ€åˆã«ã™ã¹ãã“ã¨: ãƒ‡ãƒ¼ã‚¿ã‚’è‰¯ãè¦³å¯Ÿã™ã‚‹ ã¾ãšã¯æ•£å¸ƒå›³ã‚’ä½œã‚Œ å¤šå¤‰é‡ãªã‚‰ãƒšã‚¢ãƒ—ãƒ­ãƒƒãƒˆ(æ•£å¸ƒå›³è¡Œåˆ—)ã‚’ä½œã‚Œ pandasã«ãƒšã‚¢ãƒ—ãƒ­ãƒƒãƒˆä½œæˆé–¢æ•°ãŒã‚ã‚‹ã®ã§ã€pandas.DataFrameã«å¤‰æ›ã—ã¦ä½œæ¥­ã™ã‚‹ã¨ã‚ˆã„ã€‚ ## DataFrameã¸ã®å¤‰æ› import pandas as pd iris_dataframe = pd.DataFrame(X_train, columns = iris_dataset.feature_names) æ³¨: ãƒ†ã‚­ã‚¹ãƒˆã§æŒ‡å®šã—ã¦ã„ã‚‹ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®å¤§åŠã¯å¤–è¦³èª¿æ•´ã®ãŸã‚ã®ã‚‚ã®ãªã®ã§ã€ãªãã¦ã‚‚ã„ã„ã€‚ import matplotlib.pyplot as plt import mglearn ## ãƒ—ãƒ­ãƒƒãƒˆ # pandas.scatter_matrixã¯deprecated pd.plotting.scatter_matrix( iris_dataframe, # ãƒ‡ãƒ¼ã‚¿ã®æŒ‡å®š c = y_train, # ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆã®è‰²ã‚’å‡ºåŠ›=å“ç¨®ã«å¯¾å¿œä»˜ã‘ã‚‹ figsize = (15, 15),# ç”»åƒå‡ºåŠ›ã‚µã‚¤ã‚ºã®æŒ‡å®š(ãªãã¦ã‚‚ã„ã„) marker = &#39;o&#39;, # ãƒã‚¤ãƒ³ãƒˆãƒãƒ¼ã‚«ãƒ¼ã®æŒ‡å®š(ãªãã¦ã‚‚ã„ã„) hist_kwds = {&#39;bins&#39;: 20}, # ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã‚’ä½œã‚‹é–¢æ•°ã«æ¸¡ã™å¼•æ•°ã®æŒ‡å®š(ã¨ã‚Šã‚ãˆãšãªãã¦ã‚‚ã„ã„) s = 60, # ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆã®ã‚µã‚¤ã‚ºï¼Ÿ(ãªãã¦ã‚‚ã„ã„) alpha = .8, # é€éåº¦èª¿æ•´(ãªãã¦ã‚‚ã„ã„) cmap = mglearn.cm3 # é…è‰²è¨­å®š(ã‚«ãƒ©ãƒ¼ãƒãƒƒãƒ—ã€ãªãã¦ã‚‚ã„ã„) ) ## è¡¨ç¤º plt.show() 1.6.4 æœ€åˆã®ãƒ¢ãƒ‡ãƒ«: k-æœ€è¿‘å‚æ³• è·é›¢çš„ã«è¿‘ã„ã‚„ã¤ã¯ä»²é–“ã§ã„ã„ã‚“ã˜ã‚ƒã­ï¼Ÿã«åŸºã¥ãã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã€‚ scikit-learnã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ä½¿ã†ãŸã‚ã«ã¯ã€ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã«å¯¾å¿œã™ã‚‹ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ç”Ÿæˆã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚ from sklearn.neighbors import KNeighborsClassifier knn = KNeighborsClassifier(n_neighbors = 1) # ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ç”Ÿæˆæ™‚ã«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æŒ‡å®šã§ãã‚‹ã‚‚ã®ã‚‚ã‚ã‚‹ ãƒ¢ãƒ‡ãƒ«ã«è¨“ç·´ã‚»ãƒƒãƒˆã‚’é©åˆã•ã›ã‚‹ãŸã‚ã«ã¯ã€fitãƒ¡ã‚½ãƒƒãƒ‰ã‚’å‘¼ã³å‡ºã—ã¦è¨“ç·´ã‚»ãƒƒãƒˆã‚’æ¸¡ã™ã ã‘ã§è‰¯ã„ã€‚ knn.fit(X_train, y_train) 1.6.5 äºˆæ¸¬ã‚’è¡Œã† äºˆæ¸¬ã¯predictãƒ¡ã‚½ãƒƒãƒ‰ã§è¡Œã†ã€‚é©å½“ã«ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¦äºˆæ¸¬ã—ã¦ã¿ã‚ˆã†ã€‚äºˆæ¸¬çµæœã¯ç¬¦å·åŒ–ã•ã‚ŒãŸå€¤ã«ãªã‚‹ãŒã€iris_dataset.target_namesã‚’ä½¿ã†ã¨å®Ÿéš›ã®ãƒ©ãƒ™ãƒ«åãŒåˆ†ã‹ã‚‹ã€‚ import numpy as np X_new = np.array([[5, 2.9, 1, 0.2]]) print(knn.predict(X_new)) ## [0] print(iris_dataset.target_names[knn.predict(X_new)]) ## [&#39;setosa&#39;] é©å½“ãªæ•°å­—ã‹ã‚‰äºˆæ¸¬ã—ãŸã‹ã‚‰æ­£è§£ãªã®ã‹ã©ã†ã‹åˆ†ã‹ã‚‰ãªã„ï¼ ãã®ãŸã‚ã®ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã€‚ 1.6.6 ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡ ç²¾åº¦ (accuracy): ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ãƒ©ãƒ™ãƒ«ã‚’æ­£ã—ãåˆ¤åˆ¥ã§ããŸå‰²åˆã€‚ ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã£ã¦äºˆæ¸¬ã‚’è¡Œã„ã€æ­£è§£ã¨åŒã˜ãƒ©ãƒ™ãƒ«ãŒã©ã‚Œã ã‘ã‚ã‚‹ã‹ã€ã‚’ã‚«ã‚¦ãƒ³ãƒˆã™ã‚‹ã€‚ # äºˆæ¸¬ y_pred = knn.predict(X_test) # æ¯”è¼ƒ print(y_pred == y_test) ## [ True True True True True True True True True True True True ## True True True True True True True True True True True True ## True True True True True True True True True True True True ## True False] pythonã¯æ•°å€¤è¨ˆç®—ã®éš›Trueã¯1ã€Falseã¯0ã¨ã—ã¦æ‰±ã†ã®ã§ã€y_pred == y_testã®å¹³å‡å€¤ãŒãã®ã¾ã¾ç²¾åº¦ã«ãªã‚‹ã€‚ print(np.mean(y_pred == y_test)) ## 0.9736842105263158 äºˆæ¸¬ã‹ã‚‰ç²¾åº¦è¨ˆç®—ã¾ã§ä¸€ç™ºã§ã‚„ã£ã¦ãã‚Œã‚‹ãƒ¡ã‚½ãƒƒãƒ‰ã¨ã—ã¦scoreã‚‚ã‚ã‚‹ã€‚ print(knn.score(X_test, y_test)) ## 0.9736842105263158 "],
["section-2.html", "2 æ•™å¸«ã‚ã‚Šå­¦ç¿’", " 2 æ•™å¸«ã‚ã‚Šå­¦ç¿’ å‚™ãˆã¾ã™ã€‚ import numpy as np import scipy as sp import pandas as pd import matplotlib.pyplot as plt import matplotlib matplotlib.rc(&#39;font&#39;, family=&#39;IPAexGothic&#39;) # æ—¥æœ¬èªãƒ—ãƒ­ãƒƒãƒˆè¨­å®š import mglearn "],
["section-2-1.html", "2.1 ã‚¯ãƒ©ã‚¹åˆ†é¡ã¨å›å¸°", " 2.1 ã‚¯ãƒ©ã‚¹åˆ†é¡ã¨å›å¸° æ•™å¸«ã‚ã‚Šå­¦ç¿’ã¯ã•ã‚‰ã«2ã¤ã«åˆ†ã‘ã‚‰ã‚Œã‚‹ã€‚ ã‚¯ãƒ©ã‚¹åˆ†é¡: ã‚¯ãƒ©ã‚¹ãƒ©ãƒ™ãƒ«ã‚’äºˆæ¸¬ã™ã‚‹å•é¡Œã€‚ 2ã‚¯ãƒ©ã‚¹åˆ†é¡ (binary classification): Yes/Noã¿ãŸã„ãª2æŠã€‚ ç‰‡æ–¹ã‚’é™½æ€§ (positive)ã€ã‚‚ã†ç‰‡æ–¹ã‚’é™°æ€§ (negative)ã¨ã™ã‚‹å ´åˆãŒã—ã°ã—ã°ã‚ã‚‹ã€‚ ä»–ã‚¯ãƒ©ã‚¹åˆ†é¡ (multiclass classification): ã‚‚ã£ã¨é¸æŠè‚¢å¤šã„ã‚„ã¤ã€‚ å›å¸°: é€£ç¶šå€¤ã‚’äºˆæ¸¬ã™ã‚‹å•é¡Œã€‚ 2ã¤ã‚’åŒºåˆ¥ã™ã‚‹ã®ã¯å‡ºåŠ›ãŒé€£ç¶šã‹ã©ã†ã‹ã€‚å…¥åŠ›ã¯ã©ã¡ã‚‰ã®å•é¡Œã§ã‚‚é€£ç¶šã®å ´åˆã‚‚é›¢æ•£çš„ãªå ´åˆã‚‚ã‚ã‚‹ã€‚ "],
["section-2-2.html", "2.2 æ±åŒ–ã€éå‰°é©åˆã€é©åˆä¸è¶³", " 2.2 æ±åŒ–ã€éå‰°é©åˆã€é©åˆä¸è¶³ æ±åŒ–èƒ½åŠ›: æœªçŸ¥ã®ãƒ‡ãƒ¼ã‚¿(è¨“ç·´ã«ä½¿ã£ã¦ãªã„ãƒ‡ãƒ¼ã‚¿)ã«å¯¾ã™ã‚‹æ­£ã—ã„å€¤ã‚’äºˆæ¸¬ã™ã‚‹èƒ½åŠ›ã€‚ éå‰°é©åˆ: è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¯ã‚ã£ã¡ã‚ƒæ­£ç¢ºã«äºˆæ¸¬ã§ãã‚‹ã‘ã©æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã¯ã¦ã‚“ã§ãƒ€ãƒ¡ã¨ã„ã†çŠ¶æ…‹ã€‚ é©åˆä¸è¶³: è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã™ã‚‰ã¡ã‚ƒã‚“ã¨äºˆæ¸¬ã§ãã¦ãªã„ã¨ã„ã†çŠ¶æ…‹ã€‚ ä¸€èˆ¬çš„ã«ã¯ãƒ¢ãƒ‡ãƒ«ã‚’è¤‡é›‘ã«ã™ã‚‹ã»ã©è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã«é©åˆã—ã¦ã„ãã€‚é©åˆä¸è¶³ã§ãªãã€éå‰°é©åˆã«ãªã‚‰ãªã„é©åº¦ãªãƒ¢ãƒ‡ãƒ«ã®è¤‡é›‘ã•ã®æ™‚ã«æ±åŒ–èƒ½åŠ›ãŒæœ€å¤§ã«ãªã‚‹ã€‚ãã“ã‚’ç›®æŒ‡ãã†ã€‚ 2.2.1 ãƒ¢ãƒ‡ãƒ«ã®è¤‡é›‘ã•ã¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®å¤§ãã• ãƒ¢ãƒ‡ãƒ«ãŒè¤‡é›‘ã§ã‚‚ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒå¤§ãã‘ã‚Œã°éå‰°é©åˆã‚’é¿ã‘ã‚‰ã‚Œã‚‹ã€‚ é©åº¦ãªè¤‡é›‘ã•ã®ãƒ¢ãƒ‡ãƒ«ã¨ååˆ†ã«å¤§ããªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ã†ã“ã¨ãŒæˆåŠŸã®ãƒã‚¤ãƒ³ãƒˆã€‚ "],
["section-2-3.html", "2.3 æ•™å¸«ã‚ã‚Šæ©Ÿæ¢°å­¦ç¿’ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ", " 2.3 æ•™å¸«ã‚ã‚Šæ©Ÿæ¢°å­¦ç¿’ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ  2.3.1 ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ äººå·¥çš„ãªå˜ç´”ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨ã€å®Ÿä¸–ç•Œã®å‰²ã¨è¤‡é›‘ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ã†ã€‚ 2.3.1.1 äººå·¥çš„ãªå˜ç´”ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ å˜ç´”ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯mglearnã§ç”Ÿæˆã™ã‚‹ã€‚ forge: mglearn.datasets.make_forge()ã§ç”Ÿæˆã™ã‚‹2ã‚¯ãƒ©ã‚¹åˆ†é¡å‘ã‘ãƒ‡ãƒ¼ã‚¿ã€‚ 2ã¤ã®ç‰¹å¾´é‡ã¨1ã¤ã®2å€¤ç›®çš„å¤‰æ•°ã‚’ã‚‚ã¤ã€‚ X, y = mglearn.datasets.make_forge() mglearn.discrete_scatter(X[:, 0], X[:, 1], y) plt.legend([&quot;Class 0&quot;, &quot;Class 1&quot;], loc = 4) # å‡¡ä¾‹ plt.xlabel(&quot;ç¬¬1ç‰¹å¾´é‡&quot;) plt.ylabel(&quot;ç¬¬2ç‰¹å¾´é‡&quot;) plt.show() plt.close() wave: mglearn.datasets.make_waveã§ç”Ÿæˆã™ã‚‹å›å¸°å‘ã‘ãƒ‡ãƒ¼ã‚¿ã€‚ 1ã¤ã®ç‰¹å¾´é‡ã¨1ã¤ã®ç›®çš„å¤‰æ•°ã‚’æŒã¤ã€‚ X, y = mglearn.datasets.make_wave(n_samples = 40) plt.plot(X, y, &#39;o&#39;) plt.xlabel(&quot;ç‰¹å¾´é‡&quot;) plt.xlabel(&quot;ç›®çš„å¤‰æ•°&quot;) plt.show() plt.close() 2.3.1.2 å®Ÿãƒ‡ãƒ¼ã‚¿ å®Ÿãƒ‡ãƒ¼ã‚¿ã¯scikit-learnã«å…¥ã£ã¦ã‚‹ã‚‚ã®ã‚’ä½¿ã†ã€‚ç¬¬1ç« ã§ã‚‚èª¬æ˜ã—ãŸBunchã‚¯ãƒ©ã‚¹ã«ãªã£ã¦ã„ã‚‹ã€‚ cancer: ã‚¦ã‚£ã‚¹ã‚³ãƒ³ã‚·ãƒ³ä¹³ç™Œãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ ç›®çš„å¤‰æ•°ã¯è‰¯æ€§(benign)ã¨æ‚ªæ€§(malignant)ã®2å€¤ã€‚ ç‰¹å¾´é‡ã¯30ã€‚ ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆã¯569ç‚¹ã€‚ from sklearn.datasets import load_breast_cancer cancer = load_breast_cancer() print(cancer.keys()) ## dict_keys([&#39;data&#39;, &#39;target&#39;, &#39;target_names&#39;, &#39;DESCR&#39;, &#39;feature_names&#39;]) print(cancer.data.shape) ## (569, 30) print(cancer.target_names) ## [&#39;malignant&#39; &#39;benign&#39;] print(np.bincount(cancer.target)) ## [212 357] boston_housing: 1970å¹´ä»£ã®ãƒœã‚¹ãƒˆãƒ³è¿‘éƒŠã®ä½å®…ä¾¡æ ¼ã€‚ ä½å®…ä¾¡æ ¼ã®ä¸­å¤®å€¤ãŒç›®çš„å¤‰æ•°ã€‚ ç‰¹å¾´é‡ã¯13ã€‚ ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆã¯506ç‚¹ã€‚ from sklearn.datasets import load_boston boston = load_boston() print(boston.data.shape) ## (506, 13) print(boston.feature_names) ## [&#39;CRIM&#39; &#39;ZN&#39; &#39;INDUS&#39; &#39;CHAS&#39; &#39;NOX&#39; &#39;RM&#39; &#39;AGE&#39; &#39;DIS&#39; &#39;RAD&#39; &#39;TAX&#39; &#39;PTRATIO&#39; ## &#39;B&#39; &#39;LSTAT&#39;] ç‰¹å¾´é‡åŒå£«ã®ç©ã‚’æ±‚ã‚ãŸã‚Šã—ã¦ã€æ–°ã—ã„ç‰¹å¾´é‡ã‚’å°å‡ºã™ã‚‹ã“ã¨ã‚’ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã¨å‘¼ã¶ã€‚ boston_housingã«å¯¾ã—ã€é‡è¤‡ã‚ã‚Šã§2ã¤ã®ç‰¹å¾´é‡ã®ç©ã‚’æ±‚ã‚ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æ‹¡å¼µã‚’è©¦ã¿ã‚‹ã€‚ ä½œæ¥­ãŒé¢å€’ãªã®ã§æ—¢ã«æ‹¡å¼µã—ãŸã‚‚ã®ãŒmglearn.datasets.load_extended_boston()ã§èª­ã¿è¾¼ã‚ã¾ã™ã€‚ X, y = mglearn.datasets.load_extended_boston() print(X.shape) ## (506, 104) 2.3.2 \\(k\\)-æœ€è¿‘å‚æ³• å‚™ãˆã‚ˆã†ã€‚ 2.3.3 ç·šå½¢ãƒ¢ãƒ‡ãƒ« 2.3.3.1 ç·šå½¢ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹å›å¸° ç·šå½¢ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹äºˆæ¸¬å¼ã¯â€¦ \\[\\hat{y} = w[0]\\times x[0] + w[1]\\times x[1] + ... + w[p]\\times x[p] + b\\] \\(\\hat{y}\\)ã¯äºˆæ¸¬å€¤ã§ã€\\(w\\)ã¨\\(b\\)ã¯ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã€‚\\(x\\)ã¯ã‚ã‚‹ä¸€ã¤ã®ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆã®ç‰¹å¾´é‡ã€‚ äºˆæ¸¬å€¤ã¯ã€ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆã‚’é©å½“ã«é‡ã¿ä»˜ã‘ã—ãŸã‚‚ã®ã€ã¨è¦‹ã‚‹ã“ã¨ã‚‚ã§ãã‚‹ã€‚ waveã«ç·šå½¢å›å¸°ã‚’é©ç”¨ã—ã¦ãƒ—ãƒ­ãƒƒãƒˆã—ã¦ã¿ã‚ˆã†ã€‚ mglearn.plots.plot_linear_regression_wave() ## w[0]: 0.393906 b: -0.031804 ## ## /Users/rito/myenv/lib/python3.6/site-packages/scipy/linalg/basic.py:1226: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to &#39;gelss&#39; driver. ## warnings.warn(mesg, RuntimeWarning) plt.show() ç·šå½¢ãƒ¢ãƒ‡ãƒ«ã‚’åˆ©ç”¨ã—ãŸå›å¸°ã«ã¯ã„ã‚ã„ã‚ãªã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ãŒã‚ã£ã¦ã€ãã‚Œãã‚Œä»¥ä¸‹ã®ç‚¹ã§ç•°ãªã£ã¦ã„ã‚‹ã€‚ ã©ã®ã‚ˆã†ã«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿\\(w\\)ã¨\\(b\\)ã‚’å­¦ç¿’ã™ã‚‹ã‹ã€‚ ãƒ¢ãƒ‡ãƒ«ã®è¤‡é›‘ã•ã‚’ã©ã®ã‚ˆã†ã«åˆ¶å¾¡ã™ã‚‹ã®ã‹ã€‚ 2.3.3.2 ç·šå½¢å›å¸°(é€šå¸¸æœ€å°äºŒä¹—æ³•) äºˆæ¸¬å€¤ã¨çœŸå€¤ã®å¹³å‡äºŒä¹—èª¤å·® (mean squared error) ã‚’æœ€å°ã«ã™ã‚‹ã‚ˆã†ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ±‚ã‚ã‚‹ã€‚ ç·šå½¢å›å¸°ã«ã¯è¤‡é›‘ã•ã‚’åˆ¶å¾¡ã™ã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒãªã„ã€‚ã§ããªã„ã€‚ from sklearn.model_selection import train_test_split from sklearn.linear_model import LinearRegression X, y = mglearn.datasets.make_wave(n_samples = 60) X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42) lr = LinearRegression().fit(X_train, y_train) \\(w\\)ã¯ä¿‚æ•° (coefficient)ã¨å‘¼ã°ã‚Œã€coef_ã«æ ¼ç´ã•ã‚Œã‚‹ã€‚ \\(b\\)ã¯åˆ‡ç‰‡ (intercept)ã¨å‘¼ã°ã‚Œã€intercept_ã«æ ¼ç´ã•ã‚Œã‚‹ã€‚ print(lr.coef_) ## [0.39390555] print(lr.intercept_) ## -0.03180434302675976 è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å¾—ã‚‰ã‚ŒãŸå±æ€§ã«ã‚¢ãƒ³ãƒ€ãƒ¼ã‚¹ã‚³ã‚¢ã‚’ä»˜ã‘ã‚‹ã®ã¯scikit-learnã®æ…£ç¿’ã§ã‚ã‚‹ã€‚ coef_ã¯ç‰¹å¾´é‡1ã¤ã«å¯¾ã—ã¦1ã¤ã®å€¤ã‚’ã‚‚ã¤NumPyé…åˆ—ã¨ãªã‚‹ã€‚ ç·šå½¢å›å¸°ã®æ€§èƒ½ã¯æ±ºå®šä¿‚æ•°\\(R^2\\)ã¨ã—ã¦æ±‚ã‚ã‚‰ã‚Œã‚‹ã€‚ print(lr.score(X_train, y_train)) ## 0.6700890315075756 print(lr.score(X_test, y_test)) ## 0.65933685968637 ã“ã“ã§è¨“ç·´ã‚»ãƒƒãƒˆã¨ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã®\\(R^2\\)ãŒã‚ã‚“ã¾ã‚Šé•ã‚ãªã„ã®ã¯ï¼ˆäºˆæ¸¬æ€§èƒ½ã¯ã¨ã‚‚ã‹ãï¼‰éå‰°é©åˆã—ã¦ã„ãªã„ã“ã¨ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚é€šå¸¸ã€ç‰¹å¾´é‡ãŒå¤šã„ã»ã©éå‰°é©åˆã®ãƒªã‚¹ã‚¯ãŒé«˜ã¾ã‚‹ã€‚æ‹¡å¼µã—ãŸboston_housingã§ç¢ºèªã—ã¦ã¿ã‚ˆã†ã€‚ X, y = mglearn.datasets.load_extended_boston() X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0) lr = LinearRegression().fit(X_train, y_train) \\(R^2\\)ã‚’è¨“ç·´ã‚»ãƒƒãƒˆã¨ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã§æ¯”è¼ƒã—ã¦ã¿ã‚ˆã†ã€‚ print(lr.score(X_train, y_train)) ## 0.9523526436864234 print(lr.score(X_test, y_test)) ## 0.6057754892935417 ä¸¡è€…ã«ä¹–é›¢ãŒè¦‹ã‚‰ã‚Œã‚‹ã®ã¯ã€éå‰°é©åˆã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚ ãƒ¢ãƒ‡ãƒ«ã®è¤‡é›‘ã•ã‚’åˆ¶å¾¡ã§ãã‚Œã°è‰¯ã„ã®ã ãŒã€ç·šå½¢å›å¸°ã«ã¯ãã®ãŸã‚ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒãªã„ã€‚ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å°å…¥ã™ã‚‹æ–¹æ³•ã¨ã—ã¦ãƒªãƒƒã‚¸å›å¸°ãŒã‚ã‚‹ã€‚ 2.3.3.3 ãƒªãƒƒã‚¸å›å¸° ä¿‚æ•°ãŒå¤šã„ã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ãŒè¤‡é›‘ã«ãªã‚‹ã€‚ ä¿‚æ•°ãŒ0ï¼ãã®ä¿‚æ•°ã‚’è€ƒæ…®ã—ãªã„ã€‚ ä¿‚æ•°ãŒå°ã•ã‘ã‚Œã°ãƒ¢ãƒ‡ãƒ«ã¯å˜ç´”ã«ãªã‚‹ã®ã§ã¯ğŸ¤” æ¥µç«¯ãªè©±ä¿‚æ•°ãŒå…¨éƒ¨ã‚¼ãƒ­ãªã‚‰å…¥åŠ›ã«é–¢ã‚ã‚‰ãšä¸€å®šã®å€¤(å¹³å‡ã¨ã‹)ã‚’å‡ºåŠ›ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã«ãªã‚‹ã€‚ ä¿‚æ•°ãƒ™ã‚¯ãƒˆãƒ«ã®é•·ã•ã‚’æœ€å°åŒ–ã—ã‚ˆã†ï¼â†’ãƒªãƒƒã‚¸å›å¸° from sklearn.linear_model import Ridge ridge = Ridge().fit(X_train, y_train) # ãƒ‡ãƒ¼ã‚¿ã¯æ‹¡å¼µBoston housingã®ã¾ã¾ print(ridge.score(X_train, y_train)) ## 0.8860578560395833 print(ridge.score(X_test, y_test)) ## 0.7527139600306942 è¨“ç·´ã‚»ãƒƒãƒˆã¸ã®äºˆæ¸¬èƒ½åŠ›ãŒä¸‹ãŒã£ãŸã‘ã©ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã¸ã®äºˆæ¸¬èƒ½åŠ›ãŒä¸ŠãŒã£ãŸï¼ ãƒ¢ãƒ‡ãƒ«ã‚’å˜ç´”ã«ã™ã‚‹ã“ã¨ã§æ±åŒ–èƒ½åŠ›ãŒä¸ŠãŒã£ã¦ã„ã‚‹ã€‚ ãƒªãƒƒã‚¸å›å¸°ã«ãŠã‘ã‚‹ãƒ¢ãƒ‡ãƒ«ã®å˜ç´”ã•ã‚’åˆ¶å¾¡ã™ã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: \\(\\alpha\\) å¤§ãã„ã»ã©åˆ¶ç´„ãŒå¼·ã„ = ãƒ¢ãƒ‡ãƒ«ãŒå˜ç´”ã«ãªã‚‹ sklearnã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯1.0 ä½•ãŒè‰¯ã„ã‹ã¯ãƒ‡ãƒ¼ã‚¿æ¬¡ç¬¬ã§ã€è‡ªå‹•çš„ã«ã¯èª¿æ•´ã•ã‚Œãªã„ï¼ˆå¾Œã§å¤šåˆ†ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ–¹æ³•ãŒå‡ºã¦æ¥ã‚‹ï¼‰ã€‚ ### alphaã‚’10å€ã«ã—ã¦ã¿ã‚‹ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆç”Ÿæˆæ™‚ã«æŒ‡å®š ridge10 = Ridge(alpha = 10).fit(X_train, y_train) print(ridge10.score(X_train, y_train)) ## 0.7883461511233252 print(ridge10.score(X_test, y_test)) ### alphaã‚’0.1å€ã«ã—ã¦ã¿ã‚‹ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆç”Ÿæˆæ™‚ã«æŒ‡å®š ## 0.6358967327447734 ridge01 = Ridge(alpha = .1).fit(X_train, y_train) print(ridge01.score(X_train, y_train)) ## 0.9285782082010738 print(ridge01.score(X_test, y_test)) ## 0.7717933688844855 \\(\\alpha\\)ã®å¤§ãã•ã¨ä¿‚æ•°ã®é–¢ä¿‚ã‚’ãƒ—ãƒ­ãƒƒãƒˆã—ã¦ã¿ã‚‹ã€‚\\(\\alpha\\)ãŒå¤§ãã„ã»ã©ä¿‚æ•°ã®çµ¶å¯¾å€¤ã¯å°ã•ããªã‚‹ã¯ãšâ€¦ TODO:ãƒ©ãƒ™ãƒ«ä½ç½®ã®èª¿æ•´æ–¹æ³•ã‚’èª¿ã¹ã‚‹ plt.plot(ridge.coef_, &#39;s&#39;, label=&quot;Ridge alpha=1&quot;) plt.plot(ridge10.coef_, &#39;^&#39;, label=&quot;Ridge alpha=10&quot;) plt.plot(ridge01.coef_, &#39;v&#39;, label=&quot;Ridge alpha=0.1&quot;) plt.plot(lr.coef_, &#39;o&#39;, label=&quot;LinearRegression&quot;) plt.xlabel(&quot;ä¿‚æ•°ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹&quot;) plt.ylabel(&quot;ä¿‚æ•°ã®å€¤&quot;) plt.hlines(0, 0, len(lr.coef_)) plt.ylim(-25, 25) plt.legend() plt.show() plt.close() ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã‚’å¢—ã‚„ã—ã¦ã„ãã¨ã‚¹ã‚³ã‚¢ã¯ã©ã®ã‚ˆã†ã«å¤‰åŒ–ã™ã‚‹ã‹ï¼Ÿ å­¦ç¿’æ›²ç·š (learning curve) TODO:å‡¡ä¾‹ãƒ©ãƒ™ãƒ«ã®æ›¸ãæ›ãˆæ–¹ã‚’èª¿ã¹ã‚‹ mglearn.plots.plot_ridge_n_samples() plt.xlabel(&quot;è¨“ç·´ã‚»ãƒƒãƒˆã®ã‚µã‚¤ã‚º&quot;) plt.ylabel(&quot;ã‚¹ã‚³ã‚¢(RÂ²)&quot;) plt.show() plt.close() "]
]
